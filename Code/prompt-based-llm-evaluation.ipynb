{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10521798,"sourceType":"datasetVersion","datasetId":6511962}],"dockerImageVersionId":30840,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install openai\n!pip install transformers accelerate huggingface_hub\n!pip install llamaapi\n!pip install -q -U google-generativeai\n!pip install anthropic","metadata":{"execution":{"iopub.status.busy":"2025-01-28T22:14:51.222870Z","iopub.execute_input":"2025-01-28T22:14:51.223153Z","iopub.status.idle":"2025-01-28T22:14:55.478795Z","shell.execute_reply.started":"2025-01-28T22:14:51.223132Z","shell.execute_reply":"2025-01-28T22:14:55.477912Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nfrom transformers import AutoTokenizer, AutoModelForCausalLM\nimport transformers\nfrom torch import cuda, bfloat16\nimport pandas as pd\nimport os\nfrom groq import Groq\nfrom google.api_core.exceptions import InternalServerError\nfrom openai import OpenAI\nfrom llamaapi import LlamaAPI\nimport google.generativeai as genai\nimport json\n","metadata":{"execution":{"iopub.status.busy":"2025-01-28T22:14:59.101620Z","iopub.execute_input":"2025-01-28T22:14:59.101937Z","iopub.status.idle":"2025-01-28T22:15:08.738787Z","shell.execute_reply.started":"2025-01-28T22:14:59.101904Z","shell.execute_reply":"2025-01-28T22:15:08.737802Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"base_url = \"https://api.aimlapi.com/v1\"\napi_key = \"\"\napi = OpenAI(api_key=api_key, base_url=base_url)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-28T22:15:08.740309Z","iopub.execute_input":"2025-01-28T22:15:08.740839Z","iopub.status.idle":"2025-01-28T22:15:08.744615Z","shell.execute_reply.started":"2025-01-28T22:15:08.740807Z","shell.execute_reply":"2025-01-28T22:15:08.743747Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Load the CSV file\ncsv_file_path = '/kaggle/input/souvika-madam-dataset/NewsBlog_ProthomAlo_FinalDataset.json'  \n\nwith open(csv_file_path, \"r\", encoding='utf-8') as f:\n    data = json.loads(f.read())","metadata":{"execution":{"iopub.status.busy":"2025-01-28T22:15:08.962760Z","iopub.execute_input":"2025-01-28T22:15:08.963072Z","iopub.status.idle":"2025-01-28T22:15:09.803846Z","shell.execute_reply.started":"2025-01-28T22:15:08.963040Z","shell.execute_reply":"2025-01-28T22:15:09.802722Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from transformers import AutoTokenizer\n\ndef extract_data_from_json(article):\n    title = article.get(\"Article Title\", \"\")\n    context = article.get(\"Article Text\", \"\")\n    labels = article.get(\"Article Topics\", [])\n\n    tokens = context.split()\n\n    truncated_context = \" \".join(tokens[:1000])\n    return title, truncated_context, labels\n\ndef generate_labels_with_llama(context, title, label_set):\n   \n    reserved_output_tokens = 128  # Reserve tokens for output\n    max_input_tokens = 4097 - reserved_output_tokens  # Maximum input token limit\n\n    # Define the prompt structure\n    prompt_template = \"\"\"\n    Context:\n    {context}\n\n    Title:\n    {title}\n\n    Label Set:\n    {label_set}\n\n    Task:\n    Based on the provided context and title, identify the most relevant labels from the label set. \n    Choose the labels that best represent the meaning or main idea of the context and title.\n    Return the selected labels as a comma-separated list.\n    \"\"\"\n    \n    # Format the label set as a string\n    label_set_str = ', '.join(label_set)\n    prompt = prompt_template.format(context=context, title=title, label_set=label_set_str)\n\n    try:\n        # Simulate Llama API call\n        outputs = api.chat.completions.create(\n            model=\"databricks/dbrx-instruct\",\n            messages=[\n                {\"role\": \"system\", \"content\": \"You are a helpful assistant. You are a classifier that outputs the best associated labels from the label set. Please give only that output not anything else.\"},\n                {\"role\": \"user\", \"content\": prompt},\n            ],\n            temperature=0.7,\n            max_tokens=reserved_output_tokens,\n            top_p=1.0\n        )\n\n        # Decode and process the response\n        response = outputs.choices[0].message.content\n        #print(response)\n        response = [item.strip() for item in response.split(\",\")]\n\n        # Filter the response to include only valid labels\n        selected_labels = [label for label in response if label in label_set]\n        print(selected_labels)\n        return selected_labels\n    except Exception as e:\n        print(\"Error:\", e)\n        return []\n\n\n\nlabel_set = ['চাকরিবাকরি', 'করোনাভাইরাস', 'চলচ্চিত্র ও তারকা', 'স্বাস্থ্য', 'ব্যাংক', \n             'অর্থনীতি', 'শিক্ষা', 'প্রাকৃতিক দুর্যোগ', 'আইন ও আদালত', 'কূটনীতি', \n             'শিল্প ও বাণিজ্য', 'ভ্রমণ', 'নকশা', 'ফুটবল', 'খাবারদাবার', \n             'দেশ ও রাজনীতি', 'আন্তর্জাতিক', 'দেশের খবর', 'রাশিয়া ইউক্রেন সংঘাত', \n             'ক্রিকেট', 'নারী']\n\n# Process articles\nresults = []\nfor i in range(len(data)):\n    if i % 100 == 0:\n        print(f\"Processing article {i}...\")\n    try:\n        title, context, true_labels = extract_data_from_json(data[i])\n        predicted_labels = generate_labels_with_llama(context, title, label_set)\n        results.append({\n            \"title\": title,\n            \"text\": context,\n            \"true_labels\": true_labels,\n            \"predicted_labels\": predicted_labels\n        })\n    except Exception as e:\n        print(f\"Error processing article {i}: {e}\")\n\n# Save results\noutput_file = \"/kaggle/working/DBRX_results.json\"\nwith open(output_file, 'w', encoding='utf-8') as f:\n    json.dump(results, f, ensure_ascii=False, indent=4)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-28T22:15:09.805847Z","iopub.execute_input":"2025-01-28T22:15:09.806129Z","execution_failed":"2025-01-28T22:15:16.985Z"}},"outputs":[],"execution_count":null}]}
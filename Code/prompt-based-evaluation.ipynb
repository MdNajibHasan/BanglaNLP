{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#Custom URL\n",
    "#https://llama3-1.llamameta.net/*?Policy=eyJTdGF0ZW1lbnQiOlt7InVuaXF1ZV9oYXNoIjoiN3VzdDc2amxub3F1NXA4aXRyY2U5eW40IiwiUmVzb3VyY2UiOiJodHRwczpcL1wvbGxhbWEzLTEubGxhbWFtZXRhLm5ldFwvKiIsIkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcyOTM3MTg4NX19fV19&Signature=ampJvj885mPgn02YZucFZRpiy8cR9WfRcQKGYX-oGii5scGvu2Gc6LwxeR01Bt3tsbwEseOnOhiGkYbS9NIMxVDQ-7SUsn8tkPMZIEhVmcLZPfaJwB%7EwY8J5T6FQg2PQmp5k2fw6S0RIqcRRc-XDaBC2g-eW73Pr3TGwgyF6V31B-j%7EILLC-272D02U80KovBMtOtXU4CCsRqpD-Pd11w38qV3qCVUDvOzmahkZPVL7akvwGY57Ywe15Ob4oi%7EN1NsH0ExtOwpQ25Q4XKDDw8S85PswP1J6GDKWU8wQAQJEn97KzFnL0LTV0z5g2aGyA7LcMAOMU7ks5G93MVPA4BA__&Key-Pair-Id=K15QRJLYKIFSLZ&Download-Request-ID=1075414637425324\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-31T02:01:14.116021Z",
     "iopub.status.busy": "2025-01-31T02:01:14.115386Z",
     "iopub.status.idle": "2025-01-31T02:01:23.796635Z",
     "shell.execute_reply": "2025-01-31T02:01:23.795757Z",
     "shell.execute_reply.started": "2025-01-31T02:01:14.115983Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.45.1)\n",
      "Requirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (0.34.2)\n",
      "Requirement already satisfied: huggingface_hub in /opt/conda/lib/python3.10/site-packages (0.25.1)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.15.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2024.5.15)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.20.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.4)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate) (5.9.3)\n",
      "Requirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (2.4.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (2024.6.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (4.12.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.2)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (1.13.3)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.8.30)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers accelerate huggingface_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-31T02:01:23.798614Z",
     "iopub.status.busy": "2025-01-31T02:01:23.798331Z",
     "iopub.status.idle": "2025-01-31T02:01:34.893005Z",
     "shell.execute_reply": "2025-01-31T02:01:34.891944Z",
     "shell.execute_reply.started": "2025-01-31T02:01:23.798585Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bitsandbytes\n",
      "  Downloading bitsandbytes-0.45.1-py3-none-manylinux_2_24_x86_64.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: torch~=2.0 in /opt/conda/lib/python3.10/site-packages (from bitsandbytes) (2.4.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from bitsandbytes) (1.26.4)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch~=2.0->bitsandbytes) (3.15.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch~=2.0->bitsandbytes) (4.12.2)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch~=2.0->bitsandbytes) (1.13.3)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch~=2.0->bitsandbytes) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch~=2.0->bitsandbytes) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch~=2.0->bitsandbytes) (2024.6.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch~=2.0->bitsandbytes) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch~=2.0->bitsandbytes) (1.3.0)\n",
      "Downloading bitsandbytes-0.45.1-py3-none-manylinux_2_24_x86_64.whl (69.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.7/69.7 MB\u001b[0m \u001b[31m23.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0mm\n",
      "\u001b[?25hInstalling collected packages: bitsandbytes\n",
      "Successfully installed bitsandbytes-0.45.1\n"
     ]
    }
   ],
   "source": [
    "!pip install -U bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-31T02:01:34.894735Z",
     "iopub.status.busy": "2025-01-31T02:01:34.894416Z",
     "iopub.status.idle": "2025-01-31T02:01:54.251503Z",
     "shell.execute_reply": "2025-01-31T02:01:54.250533Z",
     "shell.execute_reply.started": "2025-01-31T02:01:34.894697Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: fineGrained).\n",
      "Your token has been saved to /root/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import csv\n",
    "import torch\n",
    "import bitsandbytes as bnb\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import transformers\n",
    "from torch import cuda, bfloat16\n",
    "import pandas as pd\n",
    "import google.generativeai as genai\n",
    "import os\n",
    "import time\n",
    "#from groq import Groq\n",
    "#import openai\n",
    "from google.api_core.exceptions import InternalServerError\n",
    "import re\n",
    "from huggingface_hub import login\n",
    "from transformers import (AutoModelForCausalLM, AutoModel,\n",
    "                          AutoTokenizer, \n",
    "                          BitsAndBytesConfig, \n",
    "                          TrainingArguments, \n",
    "                          pipeline, \n",
    "                          logging)\n",
    "login(\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-31T02:01:54.253953Z",
     "iopub.status.busy": "2025-01-31T02:01:54.253457Z",
     "iopub.status.idle": "2025-01-31T02:01:55.328502Z",
     "shell.execute_reply": "2025-01-31T02:01:55.327550Z",
     "shell.execute_reply.started": "2025-01-31T02:01:54.253922Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import bitsandbytes as bnb\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import transformers\n",
    "from datasets import Dataset\n",
    "#from peft import LoraConfig, PeftConfig\n",
    "# from trl import SFTTrainer\n",
    "# from trl import setup_chat_format\n",
    "from transformers import (AutoModelForCausalLM, AutoModel,\n",
    "                          AutoTokenizer, \n",
    "                          BitsAndBytesConfig, \n",
    "                          TrainingArguments, \n",
    "                          pipeline, \n",
    "                          logging)\n",
    "from sklearn.metrics import (accuracy_score, \n",
    "                             classification_report, \n",
    "                             confusion_matrix)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from scipy import stats\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score, precision_recall_curve\n",
    "from sklearn.isotonic import IsotonicRegression       #For calibrating the probs\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import metrics   #Additional scklearn functions\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import plotly.express as px\n",
    "from sklearn.metrics import RocCurveDisplay\n",
    "\n",
    "\n",
    "\n",
    "# There are important!\n",
    "torch.backends.cuda.enable_mem_efficient_sdp(False)\n",
    "torch.backends.cuda.enable_flash_sdp(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-31T02:01:55.330494Z",
     "iopub.status.busy": "2025-01-31T02:01:55.329758Z",
     "iopub.status.idle": "2025-01-31T02:01:55.334729Z",
     "shell.execute_reply": "2025-01-31T02:01:55.333845Z",
     "shell.execute_reply.started": "2025-01-31T02:01:55.330465Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from scipy import spatial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-31T02:01:55.336534Z",
     "iopub.status.busy": "2025-01-31T02:01:55.335919Z",
     "iopub.status.idle": "2025-01-31T02:01:55.348048Z",
     "shell.execute_reply": "2025-01-31T02:01:55.347157Z",
     "shell.execute_reply.started": "2025-01-31T02:01:55.336495Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import json\n",
    "\n",
    "ArticleEmbedding = []\n",
    "\n",
    "def compute_article_embedding(embed, tokenizer, batch_size=10, max_length=512):\n",
    "    if tokenizer.pad_token is None:\n",
    "        tokenizer.pad_token = tokenizer.eos_token\n",
    "    with open(\"/kaggle/input/dataset-multi-class-classification/NewsBlog_ProthomAlo_FinalDataset.json\", \"r\", encoding='utf-8') as f:\n",
    "        data = json.loads(f.read())\n",
    "        \n",
    "        embed.eval()  # Set the model to evaluation mode\n",
    "        \n",
    "        # Process articles in batches to avoid memory overflow\n",
    "        for l in range(0, 7245, batch_size):\n",
    "            print(f\"Processing batch {l//batch_size + 1}\")\n",
    "            batch_data = data[l:l + batch_size]  # Process a batch of articles\n",
    "            \n",
    "            for article_data in batch_data:\n",
    "                article = {}\n",
    "                article_text = article_data['Article Text']\n",
    "                article['Article Text'] = article_text\n",
    "\n",
    "                # Tokenize with truncation and padding\n",
    "                inputs = tokenizer(article_text, return_tensors=\"pt\", truncation=True, max_length=max_length, padding=\"max_length\")\n",
    "\n",
    "                # Get model output without calculating gradients\n",
    "                with torch.no_grad():\n",
    "                    output = embed(**inputs, output_hidden_states=True)\n",
    "\n",
    "                # Extract the last hidden state and apply mean pooling over the tokens\n",
    "                last_hidden_state = output.hidden_states[-1]  # Use the last hidden state\n",
    "                article_embedding = torch.mean(last_hidden_state, dim=1).squeeze()  # Mean pooling over the tokens\n",
    "\n",
    "                # Store the article embedding and label\n",
    "                article['Article Embedding'] = article_embedding.cpu().numpy()  # Convert tensor to numpy array\n",
    "                article['Label'] = article_data.get('Article Topics', None)  # Get label if available\n",
    "\n",
    "                # Append the processed article to the list\n",
    "                ArticleEmbedding.append(article)\n",
    "    \n",
    "    return ArticleEmbedding\n",
    "\n",
    "# Call the function with your model and tokenizer\n",
    "# ArticleEmbedding = compute_article_embedding(model, tokenizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-31T02:01:55.349380Z",
     "iopub.status.busy": "2025-01-31T02:01:55.349076Z",
     "iopub.status.idle": "2025-01-31T02:01:55.362350Z",
     "shell.execute_reply": "2025-01-31T02:01:55.361507Z",
     "shell.execute_reply.started": "2025-01-31T02:01:55.349347Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "            # try:\n",
    "            #     # Your code here\n",
    "            # except Exception as e:\n",
    "            #     print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-31T02:01:55.363457Z",
     "iopub.status.busy": "2025-01-31T02:01:55.363230Z",
     "iopub.status.idle": "2025-01-31T02:01:55.373457Z",
     "shell.execute_reply": "2025-01-31T02:01:55.372666Z",
     "shell.execute_reply.started": "2025-01-31T02:01:55.363434Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=False,  #False\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=\"float16\" #\"float16\", torch.float16,\n",
    "    #load_in_8bit_fp32_cpu_offload=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-31T02:01:55.374744Z",
     "iopub.status.busy": "2025-01-31T02:01:55.374458Z",
     "iopub.status.idle": "2025-01-31T02:01:55.386846Z",
     "shell.execute_reply": "2025-01-31T02:01:55.386098Z",
     "shell.execute_reply.started": "2025-01-31T02:01:55.374712Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# import torch\n",
    "\n",
    "# # Initialize an empty list to store the embeddings\n",
    "# ArticleEmbedding = []\n",
    "\n",
    "# def compute_article_embedding(embed, tokenizer):\n",
    "#     # Load the dataset from the JSON file\n",
    "#     with open(\"/kaggle/input/dataset-multi-class-classification/NewsBlog_ProthomAlo_FinalDataset.json\", \"r\") as f:\n",
    "#         data = json.loads(f.read())\n",
    "        \n",
    "#         # Set the model to evaluation mode (disables dropout, etc.)\n",
    "#         embed.eval()\n",
    "        \n",
    "#         # Loop through each article in the dataset\n",
    "#         for l, article_data in enumerate(data):\n",
    "#             article = dict()\n",
    "#             print(f\"Processing article number: {l + 1}\")\n",
    "            \n",
    "#             # Get the article text\n",
    "#             article_text = article_data['Article Text']\n",
    "            \n",
    "#             # Tokenize the article text\n",
    "#             inputs = tokenizer(article_text, return_tensors=\"pt\", truncation=True, max_length=256)  # Limit to 512 tokens\n",
    "\n",
    "            \n",
    "#             # Perform inference without storing gradients\n",
    "#             with torch.no_grad():\n",
    "#                 embedding = embed(**inputs, output_hidden_states=True)\n",
    "#                 hidden_state = embedding.hidden_states[-1]\n",
    "#             # Take the mean of the embedding along the sequence dimension (dim=1) to get a single vector for the article\n",
    "#             article_embedding = hidden_state.mean(dim=1).squeeze()\n",
    "            \n",
    "#             # Add the embedding and other details to the article dictionary\n",
    "#             article['Article Text'] = article_text\n",
    "#             article['Article Embedding'] = article_embedding\n",
    "#             article['Label'] = article_data.get('Concept')\n",
    "            \n",
    "#             # Append the processed article to the list of embeddings\n",
    "#             ArticleEmbedding.append(article)\n",
    "#             torch.cuda.empty_cache()\n",
    "#     return ArticleEmbedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-31T02:01:55.389630Z",
     "iopub.status.busy": "2025-01-31T02:01:55.389378Z",
     "iopub.status.idle": "2025-01-31T02:01:55.402249Z",
     "shell.execute_reply": "2025-01-31T02:01:55.401431Z",
     "shell.execute_reply.started": "2025-01-31T02:01:55.389606Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def compute_label_embedding(embed, tokenizer):\n",
    "    print(\"inside label embedding\")\n",
    "    with open(\"/kaggle/input/dataset-multi-class-classification/Keyword_BengaliNews.json\", \"r\") as f:\n",
    "        key = json.loads(f.read())\n",
    "        \n",
    "        for i in range(len(key)):\n",
    "            label_embedding = 0\n",
    "            label = key[i]['Keyword'][0]\n",
    "            \n",
    "            for j in range(len(key[i]['Keyword'])):\n",
    "                # Tokenize the keyword\n",
    "                inputs = tokenizer(key[i]['Keyword'][j], return_tensors=\"pt\", truncation=True, max_length=512)\n",
    "                \n",
    "                # Perform inference without gradients\n",
    "                with torch.no_grad():\n",
    "                    # Forward pass through the model\n",
    "                    outputs = embed(**inputs, output_hidden_states=True)\n",
    "                    \n",
    "                    # Extract the last hidden state tensor\n",
    "                    hidden_state = outputs.hidden_states[-1]  # This gives you the tensor\n",
    "                    \n",
    "                    # Mean pooling across the sequence dimension (dim=1)\n",
    "                    keyword_embedding = hidden_state.mean(dim=1).squeeze()\n",
    "                    \n",
    "                    # Accumulate embeddings\n",
    "                    label_embedding += keyword_embedding\n",
    "            \n",
    "            # Store averaged embeddings\n",
    "            LabelEmbedding[label] = label_embedding / len(key[i]['Keyword'])\n",
    "    \n",
    "    return LabelEmbedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-31T02:01:55.403364Z",
     "iopub.status.busy": "2025-01-31T02:01:55.403116Z",
     "iopub.status.idle": "2025-01-31T02:01:55.417629Z",
     "shell.execute_reply": "2025-01-31T02:01:55.416818Z",
     "shell.execute_reply.started": "2025-01-31T02:01:55.403325Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# LabelEmbedding={}\n",
    "# # label_path=\"\"\n",
    "\n",
    "# def compute_label_embedding(embed, tokenizer):\n",
    "#     print(\"inside label embedding\")\n",
    "#     with open(\"/kaggle/input/dataset-multi-class-classification/Keyword_BengaliNews.json\", \"r\", encoding='utf-8') as f:\n",
    "#         key = json.loads(f.read())\n",
    "#         for i in range(0, len(key)):\n",
    "#             label_embedding = 0\n",
    "#             label = key[i]['Keyword'][0]\n",
    "#             for j in range(0, len(key[i]['Keyword'])):\n",
    "#                  #p = []\n",
    "#                  inputs = tokenizer(key[i]['Keyword'][j], return_tensors=\"pt\")\n",
    "#                  with torch.no_grad():\n",
    "#                      outputs = embed(**inputs, output_hidden_states=True)\n",
    "#                      hidden_states = outputs.hidden_states[-1]  # Get the last hidden layer\n",
    "#                  keyword_embedding = hidden_states.mean(dim=1)  # Mean pooling over sequence length\n",
    "#                  #print(keyword_embedding)\n",
    "#                  # Accumulate the embeddings\n",
    "#                  label_embedding += keyword_embedding\n",
    "#             LabelEmbedding[label] = label_embedding / len(key[i]['Keyword'])\n",
    "#     return LabelEmbedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-31T02:01:55.419141Z",
     "iopub.status.busy": "2025-01-31T02:01:55.418824Z",
     "iopub.status.idle": "2025-01-31T02:01:55.432311Z",
     "shell.execute_reply": "2025-01-31T02:01:55.431706Z",
     "shell.execute_reply.started": "2025-01-31T02:01:55.419114Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# import json\n",
    "# import torch\n",
    "# from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "# LabelEmbedding = []\n",
    "# batch_size = 1  # Reduce batch size to minimize memory usage\n",
    "\n",
    "# def compute_label_embedding2(embed, tokenizer, batch_size=10):\n",
    "#     print(\"inside label embedding\")\n",
    "    \n",
    "#     # Set pad token if not already set\n",
    "#     if tokenizer.pad_token is None:\n",
    "#         tokenizer.pad_token = tokenizer.eos_token\n",
    "    \n",
    "#     with open(\"/kaggle/input/dataset-multi-class-classification/Keyword_BengaliNews.json\", \"r\") as f:\n",
    "#         key = json.loads(f.read())\n",
    "    \n",
    "#     with open(\"/kaggle/input/dataset-multi-class-classification/NewsBlog_ProthomAlo_annotated_explicitly.json\", \"r\") as f:\n",
    "#         data = json.loads(f.read())\n",
    "    \n",
    "#     # Clear CUDA memory before starting\n",
    "#     torch.cuda.empty_cache()\n",
    "\n",
    "#     for i in range(0, len(key)):\n",
    "#         count = 0\n",
    "#         label_embedding = 0\n",
    "#         label = key[i]['Keyword'][0]\n",
    "#         print(\"Working on key \",i)\n",
    "#         # Process data in batches to avoid memory overload\n",
    "#         for batch_start in range(0, 7245, batch_size):\n",
    "#             batch = data[batch_start:batch_start + batch_size]\n",
    "            \n",
    "#             for l in batch:\n",
    "#                 if label in l['Explicit Article Topics']:\n",
    "#                     inputs = tokenizer([l['Article Text']], return_tensors=\"pt\", padding=True, truncation=True, max_length=512)  # Truncate to 512 tokens\n",
    "#                     inputs = {key: value.to('cuda') for key, value in inputs.items()}  # Move inputs to GPU\n",
    "                    \n",
    "#                     with torch.no_grad():  # Disable gradient calculations for memory savings\n",
    "#                         outputs = embed(**inputs, output_hidden_states=True)\n",
    "#                         hidden_states = outputs.hidden_states[-1]\n",
    "                    \n",
    "#                     keyword_embedding = hidden_states.mean(dim=1)\n",
    "#                     label_embedding += keyword_embedding\n",
    "#                     count += 1\n",
    "            \n",
    "#             # Clear CUDA cache after each batch\n",
    "#             torch.cuda.empty_cache()\n",
    "        \n",
    "#         if count > 0:\n",
    "#             LabelEmbedding[label] = label_embedding / count\n",
    "#         else:\n",
    "#             # If no matching articles, calculate from the keyword directly\n",
    "#             for j in range(0, len(key[i]['Keyword'])):\n",
    "#                 inputs = tokenizer([key[i]['Keyword'][j]], return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "#                 inputs = {key: value.to('cuda') for key, value in inputs.items()}  # Move inputs to GPU\n",
    "                \n",
    "#                 with torch.no_grad():\n",
    "#                     outputs = embed(**inputs, output_hidden_states=True)\n",
    "#                     hidden_states = outputs.hidden_states[-1]\n",
    "                \n",
    "#                 keyword_embedding = hidden_states.mean(dim=1)\n",
    "#                 label_embedding += keyword_embedding\n",
    "\n",
    "#             LabelEmbedding[label] = label_embedding / len(key[i]['Keyword'])\n",
    "\n",
    "#     return LabelEmbedding\n",
    "\n",
    "# # Load model and tokenizer\n",
    "# # model_name = \"path_to_your_model\"\n",
    "# # model = AutoModel.from_pretrained(model_name).to('cuda')  # Load model to GPU\n",
    "# #tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# # Enable gradient checkpointing to save memory\n",
    "\n",
    "\n",
    "# # Call the function\n",
    "# #LabelEmbedding = compute_label_embedding2(model, tokenizer)\n",
    "\n",
    "# # Clear CUDA memory after processing\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-31T02:01:55.433526Z",
     "iopub.status.busy": "2025-01-31T02:01:55.433286Z",
     "iopub.status.idle": "2025-01-31T02:23:50.047610Z",
     "shell.execute_reply": "2025-01-31T02:23:50.046435Z",
     "shell.execute_reply.started": "2025-01-31T02:01:55.433502Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b39457ea009479580f48d0d791b08d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/638 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0dc55fb14274eebb4d75fb914fd94c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin.index.json:   0%|          | 0.00/90.4k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74a67afe4d364966831184b458a01b0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5873a55745c4c2aa184fa9bf42b53d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model-00001-of-00003.bin:   0%|          | 0.00/9.93G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f73fdbf8556146dfac589844fac742e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model-00002-of-00003.bin:   0%|          | 0.00/9.99G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21cc1f4ea8a742c6b00c5ba70c0b2f84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model-00003-of-00003.bin:   0%|          | 0.00/6.99G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32e187c6c7ce46aa94e7d03ddcc0e3bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at BanglaLLM/bangla-llama-13b-instruct-v0.1 were not used when initializing LlamaForCausalLM: ['model.layers.0.mlp.down_proj.base_layer.weight', 'model.layers.0.mlp.down_proj.lora_A.default.weight', 'model.layers.0.mlp.down_proj.lora_B.default.weight', 'model.layers.0.mlp.gate_proj.base_layer.weight', 'model.layers.0.mlp.gate_proj.lora_A.default.weight', 'model.layers.0.mlp.gate_proj.lora_B.default.weight', 'model.layers.0.mlp.up_proj.base_layer.weight', 'model.layers.0.mlp.up_proj.lora_A.default.weight', 'model.layers.0.mlp.up_proj.lora_B.default.weight', 'model.layers.0.self_attn.k_proj.base_layer.weight', 'model.layers.0.self_attn.k_proj.lora_A.default.weight', 'model.layers.0.self_attn.k_proj.lora_B.default.weight', 'model.layers.0.self_attn.o_proj.base_layer.weight', 'model.layers.0.self_attn.o_proj.lora_A.default.weight', 'model.layers.0.self_attn.o_proj.lora_B.default.weight', 'model.layers.0.self_attn.q_proj.base_layer.weight', 'model.layers.0.self_attn.q_proj.lora_A.default.weight', 'model.layers.0.self_attn.q_proj.lora_B.default.weight', 'model.layers.0.self_attn.v_proj.base_layer.weight', 'model.layers.0.self_attn.v_proj.lora_A.default.weight', 'model.layers.0.self_attn.v_proj.lora_B.default.weight', 'model.layers.1.mlp.down_proj.base_layer.weight', 'model.layers.1.mlp.down_proj.lora_A.default.weight', 'model.layers.1.mlp.down_proj.lora_B.default.weight', 'model.layers.1.mlp.gate_proj.base_layer.weight', 'model.layers.1.mlp.gate_proj.lora_A.default.weight', 'model.layers.1.mlp.gate_proj.lora_B.default.weight', 'model.layers.1.mlp.up_proj.base_layer.weight', 'model.layers.1.mlp.up_proj.lora_A.default.weight', 'model.layers.1.mlp.up_proj.lora_B.default.weight', 'model.layers.1.self_attn.k_proj.base_layer.weight', 'model.layers.1.self_attn.k_proj.lora_A.default.weight', 'model.layers.1.self_attn.k_proj.lora_B.default.weight', 'model.layers.1.self_attn.o_proj.base_layer.weight', 'model.layers.1.self_attn.o_proj.lora_A.default.weight', 'model.layers.1.self_attn.o_proj.lora_B.default.weight', 'model.layers.1.self_attn.q_proj.base_layer.weight', 'model.layers.1.self_attn.q_proj.lora_A.default.weight', 'model.layers.1.self_attn.q_proj.lora_B.default.weight', 'model.layers.1.self_attn.v_proj.base_layer.weight', 'model.layers.1.self_attn.v_proj.lora_A.default.weight', 'model.layers.1.self_attn.v_proj.lora_B.default.weight', 'model.layers.10.mlp.down_proj.base_layer.weight', 'model.layers.10.mlp.down_proj.lora_A.default.weight', 'model.layers.10.mlp.down_proj.lora_B.default.weight', 'model.layers.10.mlp.gate_proj.base_layer.weight', 'model.layers.10.mlp.gate_proj.lora_A.default.weight', 'model.layers.10.mlp.gate_proj.lora_B.default.weight', 'model.layers.10.mlp.up_proj.base_layer.weight', 'model.layers.10.mlp.up_proj.lora_A.default.weight', 'model.layers.10.mlp.up_proj.lora_B.default.weight', 'model.layers.10.self_attn.k_proj.base_layer.weight', 'model.layers.10.self_attn.k_proj.lora_A.default.weight', 'model.layers.10.self_attn.k_proj.lora_B.default.weight', 'model.layers.10.self_attn.o_proj.base_layer.weight', 'model.layers.10.self_attn.o_proj.lora_A.default.weight', 'model.layers.10.self_attn.o_proj.lora_B.default.weight', 'model.layers.10.self_attn.q_proj.base_layer.weight', 'model.layers.10.self_attn.q_proj.lora_A.default.weight', 'model.layers.10.self_attn.q_proj.lora_B.default.weight', 'model.layers.10.self_attn.v_proj.base_layer.weight', 'model.layers.10.self_attn.v_proj.lora_A.default.weight', 'model.layers.10.self_attn.v_proj.lora_B.default.weight', 'model.layers.11.mlp.down_proj.base_layer.weight', 'model.layers.11.mlp.down_proj.lora_A.default.weight', 'model.layers.11.mlp.down_proj.lora_B.default.weight', 'model.layers.11.mlp.gate_proj.base_layer.weight', 'model.layers.11.mlp.gate_proj.lora_A.default.weight', 'model.layers.11.mlp.gate_proj.lora_B.default.weight', 'model.layers.11.mlp.up_proj.base_layer.weight', 'model.layers.11.mlp.up_proj.lora_A.default.weight', 'model.layers.11.mlp.up_proj.lora_B.default.weight', 'model.layers.11.self_attn.k_proj.base_layer.weight', 'model.layers.11.self_attn.k_proj.lora_A.default.weight', 'model.layers.11.self_attn.k_proj.lora_B.default.weight', 'model.layers.11.self_attn.o_proj.base_layer.weight', 'model.layers.11.self_attn.o_proj.lora_A.default.weight', 'model.layers.11.self_attn.o_proj.lora_B.default.weight', 'model.layers.11.self_attn.q_proj.base_layer.weight', 'model.layers.11.self_attn.q_proj.lora_A.default.weight', 'model.layers.11.self_attn.q_proj.lora_B.default.weight', 'model.layers.11.self_attn.v_proj.base_layer.weight', 'model.layers.11.self_attn.v_proj.lora_A.default.weight', 'model.layers.11.self_attn.v_proj.lora_B.default.weight', 'model.layers.12.mlp.down_proj.base_layer.weight', 'model.layers.12.mlp.down_proj.lora_A.default.weight', 'model.layers.12.mlp.down_proj.lora_B.default.weight', 'model.layers.12.mlp.gate_proj.base_layer.weight', 'model.layers.12.mlp.gate_proj.lora_A.default.weight', 'model.layers.12.mlp.gate_proj.lora_B.default.weight', 'model.layers.12.mlp.up_proj.base_layer.weight', 'model.layers.12.mlp.up_proj.lora_A.default.weight', 'model.layers.12.mlp.up_proj.lora_B.default.weight', 'model.layers.12.self_attn.k_proj.base_layer.weight', 'model.layers.12.self_attn.k_proj.lora_A.default.weight', 'model.layers.12.self_attn.k_proj.lora_B.default.weight', 'model.layers.12.self_attn.o_proj.base_layer.weight', 'model.layers.12.self_attn.o_proj.lora_A.default.weight', 'model.layers.12.self_attn.o_proj.lora_B.default.weight', 'model.layers.12.self_attn.q_proj.base_layer.weight', 'model.layers.12.self_attn.q_proj.lora_A.default.weight', 'model.layers.12.self_attn.q_proj.lora_B.default.weight', 'model.layers.12.self_attn.v_proj.base_layer.weight', 'model.layers.12.self_attn.v_proj.lora_A.default.weight', 'model.layers.12.self_attn.v_proj.lora_B.default.weight', 'model.layers.13.mlp.down_proj.base_layer.weight', 'model.layers.13.mlp.down_proj.lora_A.default.weight', 'model.layers.13.mlp.down_proj.lora_B.default.weight', 'model.layers.13.mlp.gate_proj.base_layer.weight', 'model.layers.13.mlp.gate_proj.lora_A.default.weight', 'model.layers.13.mlp.gate_proj.lora_B.default.weight', 'model.layers.13.mlp.up_proj.base_layer.weight', 'model.layers.13.mlp.up_proj.lora_A.default.weight', 'model.layers.13.mlp.up_proj.lora_B.default.weight', 'model.layers.13.self_attn.k_proj.base_layer.weight', 'model.layers.13.self_attn.k_proj.lora_A.default.weight', 'model.layers.13.self_attn.k_proj.lora_B.default.weight', 'model.layers.13.self_attn.o_proj.base_layer.weight', 'model.layers.13.self_attn.o_proj.lora_A.default.weight', 'model.layers.13.self_attn.o_proj.lora_B.default.weight', 'model.layers.13.self_attn.q_proj.base_layer.weight', 'model.layers.13.self_attn.q_proj.lora_A.default.weight', 'model.layers.13.self_attn.q_proj.lora_B.default.weight', 'model.layers.13.self_attn.v_proj.base_layer.weight', 'model.layers.13.self_attn.v_proj.lora_A.default.weight', 'model.layers.13.self_attn.v_proj.lora_B.default.weight', 'model.layers.14.mlp.down_proj.base_layer.weight', 'model.layers.14.mlp.down_proj.lora_A.default.weight', 'model.layers.14.mlp.down_proj.lora_B.default.weight', 'model.layers.14.mlp.gate_proj.base_layer.weight', 'model.layers.14.mlp.gate_proj.lora_A.default.weight', 'model.layers.14.mlp.gate_proj.lora_B.default.weight', 'model.layers.14.mlp.up_proj.base_layer.weight', 'model.layers.14.mlp.up_proj.lora_A.default.weight', 'model.layers.14.mlp.up_proj.lora_B.default.weight', 'model.layers.14.self_attn.k_proj.base_layer.weight', 'model.layers.14.self_attn.k_proj.lora_A.default.weight', 'model.layers.14.self_attn.k_proj.lora_B.default.weight', 'model.layers.14.self_attn.o_proj.base_layer.weight', 'model.layers.14.self_attn.o_proj.lora_A.default.weight', 'model.layers.14.self_attn.o_proj.lora_B.default.weight', 'model.layers.14.self_attn.q_proj.base_layer.weight', 'model.layers.14.self_attn.q_proj.lora_A.default.weight', 'model.layers.14.self_attn.q_proj.lora_B.default.weight', 'model.layers.14.self_attn.v_proj.base_layer.weight', 'model.layers.14.self_attn.v_proj.lora_A.default.weight', 'model.layers.14.self_attn.v_proj.lora_B.default.weight', 'model.layers.15.mlp.down_proj.base_layer.weight', 'model.layers.15.mlp.down_proj.lora_A.default.weight', 'model.layers.15.mlp.down_proj.lora_B.default.weight', 'model.layers.15.mlp.gate_proj.base_layer.weight', 'model.layers.15.mlp.gate_proj.lora_A.default.weight', 'model.layers.15.mlp.gate_proj.lora_B.default.weight', 'model.layers.15.mlp.up_proj.base_layer.weight', 'model.layers.15.mlp.up_proj.lora_A.default.weight', 'model.layers.15.mlp.up_proj.lora_B.default.weight', 'model.layers.15.self_attn.k_proj.base_layer.weight', 'model.layers.15.self_attn.k_proj.lora_A.default.weight', 'model.layers.15.self_attn.k_proj.lora_B.default.weight', 'model.layers.15.self_attn.o_proj.base_layer.weight', 'model.layers.15.self_attn.o_proj.lora_A.default.weight', 'model.layers.15.self_attn.o_proj.lora_B.default.weight', 'model.layers.15.self_attn.q_proj.base_layer.weight', 'model.layers.15.self_attn.q_proj.lora_A.default.weight', 'model.layers.15.self_attn.q_proj.lora_B.default.weight', 'model.layers.15.self_attn.v_proj.base_layer.weight', 'model.layers.15.self_attn.v_proj.lora_A.default.weight', 'model.layers.15.self_attn.v_proj.lora_B.default.weight', 'model.layers.16.mlp.down_proj.base_layer.weight', 'model.layers.16.mlp.down_proj.lora_A.default.weight', 'model.layers.16.mlp.down_proj.lora_B.default.weight', 'model.layers.16.mlp.gate_proj.base_layer.weight', 'model.layers.16.mlp.gate_proj.lora_A.default.weight', 'model.layers.16.mlp.gate_proj.lora_B.default.weight', 'model.layers.16.mlp.up_proj.base_layer.weight', 'model.layers.16.mlp.up_proj.lora_A.default.weight', 'model.layers.16.mlp.up_proj.lora_B.default.weight', 'model.layers.16.self_attn.k_proj.base_layer.weight', 'model.layers.16.self_attn.k_proj.lora_A.default.weight', 'model.layers.16.self_attn.k_proj.lora_B.default.weight', 'model.layers.16.self_attn.o_proj.base_layer.weight', 'model.layers.16.self_attn.o_proj.lora_A.default.weight', 'model.layers.16.self_attn.o_proj.lora_B.default.weight', 'model.layers.16.self_attn.q_proj.base_layer.weight', 'model.layers.16.self_attn.q_proj.lora_A.default.weight', 'model.layers.16.self_attn.q_proj.lora_B.default.weight', 'model.layers.16.self_attn.v_proj.base_layer.weight', 'model.layers.16.self_attn.v_proj.lora_A.default.weight', 'model.layers.16.self_attn.v_proj.lora_B.default.weight', 'model.layers.17.mlp.down_proj.base_layer.weight', 'model.layers.17.mlp.down_proj.lora_A.default.weight', 'model.layers.17.mlp.down_proj.lora_B.default.weight', 'model.layers.17.mlp.gate_proj.base_layer.weight', 'model.layers.17.mlp.gate_proj.lora_A.default.weight', 'model.layers.17.mlp.gate_proj.lora_B.default.weight', 'model.layers.17.mlp.up_proj.base_layer.weight', 'model.layers.17.mlp.up_proj.lora_A.default.weight', 'model.layers.17.mlp.up_proj.lora_B.default.weight', 'model.layers.17.self_attn.k_proj.base_layer.weight', 'model.layers.17.self_attn.k_proj.lora_A.default.weight', 'model.layers.17.self_attn.k_proj.lora_B.default.weight', 'model.layers.17.self_attn.o_proj.base_layer.weight', 'model.layers.17.self_attn.o_proj.lora_A.default.weight', 'model.layers.17.self_attn.o_proj.lora_B.default.weight', 'model.layers.17.self_attn.q_proj.base_layer.weight', 'model.layers.17.self_attn.q_proj.lora_A.default.weight', 'model.layers.17.self_attn.q_proj.lora_B.default.weight', 'model.layers.17.self_attn.v_proj.base_layer.weight', 'model.layers.17.self_attn.v_proj.lora_A.default.weight', 'model.layers.17.self_attn.v_proj.lora_B.default.weight', 'model.layers.18.mlp.down_proj.base_layer.weight', 'model.layers.18.mlp.down_proj.lora_A.default.weight', 'model.layers.18.mlp.down_proj.lora_B.default.weight', 'model.layers.18.mlp.gate_proj.base_layer.weight', 'model.layers.18.mlp.gate_proj.lora_A.default.weight', 'model.layers.18.mlp.gate_proj.lora_B.default.weight', 'model.layers.18.mlp.up_proj.base_layer.weight', 'model.layers.18.mlp.up_proj.lora_A.default.weight', 'model.layers.18.mlp.up_proj.lora_B.default.weight', 'model.layers.18.self_attn.k_proj.base_layer.weight', 'model.layers.18.self_attn.k_proj.lora_A.default.weight', 'model.layers.18.self_attn.k_proj.lora_B.default.weight', 'model.layers.18.self_attn.o_proj.base_layer.weight', 'model.layers.18.self_attn.o_proj.lora_A.default.weight', 'model.layers.18.self_attn.o_proj.lora_B.default.weight', 'model.layers.18.self_attn.q_proj.base_layer.weight', 'model.layers.18.self_attn.q_proj.lora_A.default.weight', 'model.layers.18.self_attn.q_proj.lora_B.default.weight', 'model.layers.18.self_attn.v_proj.base_layer.weight', 'model.layers.18.self_attn.v_proj.lora_A.default.weight', 'model.layers.18.self_attn.v_proj.lora_B.default.weight', 'model.layers.19.mlp.down_proj.base_layer.weight', 'model.layers.19.mlp.down_proj.lora_A.default.weight', 'model.layers.19.mlp.down_proj.lora_B.default.weight', 'model.layers.19.mlp.gate_proj.base_layer.weight', 'model.layers.19.mlp.gate_proj.lora_A.default.weight', 'model.layers.19.mlp.gate_proj.lora_B.default.weight', 'model.layers.19.mlp.up_proj.base_layer.weight', 'model.layers.19.mlp.up_proj.lora_A.default.weight', 'model.layers.19.mlp.up_proj.lora_B.default.weight', 'model.layers.19.self_attn.k_proj.base_layer.weight', 'model.layers.19.self_attn.k_proj.lora_A.default.weight', 'model.layers.19.self_attn.k_proj.lora_B.default.weight', 'model.layers.19.self_attn.o_proj.base_layer.weight', 'model.layers.19.self_attn.o_proj.lora_A.default.weight', 'model.layers.19.self_attn.o_proj.lora_B.default.weight', 'model.layers.19.self_attn.q_proj.base_layer.weight', 'model.layers.19.self_attn.q_proj.lora_A.default.weight', 'model.layers.19.self_attn.q_proj.lora_B.default.weight', 'model.layers.19.self_attn.v_proj.base_layer.weight', 'model.layers.19.self_attn.v_proj.lora_A.default.weight', 'model.layers.19.self_attn.v_proj.lora_B.default.weight', 'model.layers.2.mlp.down_proj.base_layer.weight', 'model.layers.2.mlp.down_proj.lora_A.default.weight', 'model.layers.2.mlp.down_proj.lora_B.default.weight', 'model.layers.2.mlp.gate_proj.base_layer.weight', 'model.layers.2.mlp.gate_proj.lora_A.default.weight', 'model.layers.2.mlp.gate_proj.lora_B.default.weight', 'model.layers.2.mlp.up_proj.base_layer.weight', 'model.layers.2.mlp.up_proj.lora_A.default.weight', 'model.layers.2.mlp.up_proj.lora_B.default.weight', 'model.layers.2.self_attn.k_proj.base_layer.weight', 'model.layers.2.self_attn.k_proj.lora_A.default.weight', 'model.layers.2.self_attn.k_proj.lora_B.default.weight', 'model.layers.2.self_attn.o_proj.base_layer.weight', 'model.layers.2.self_attn.o_proj.lora_A.default.weight', 'model.layers.2.self_attn.o_proj.lora_B.default.weight', 'model.layers.2.self_attn.q_proj.base_layer.weight', 'model.layers.2.self_attn.q_proj.lora_A.default.weight', 'model.layers.2.self_attn.q_proj.lora_B.default.weight', 'model.layers.2.self_attn.v_proj.base_layer.weight', 'model.layers.2.self_attn.v_proj.lora_A.default.weight', 'model.layers.2.self_attn.v_proj.lora_B.default.weight', 'model.layers.20.mlp.down_proj.base_layer.weight', 'model.layers.20.mlp.down_proj.lora_A.default.weight', 'model.layers.20.mlp.down_proj.lora_B.default.weight', 'model.layers.20.mlp.gate_proj.base_layer.weight', 'model.layers.20.mlp.gate_proj.lora_A.default.weight', 'model.layers.20.mlp.gate_proj.lora_B.default.weight', 'model.layers.20.mlp.up_proj.base_layer.weight', 'model.layers.20.mlp.up_proj.lora_A.default.weight', 'model.layers.20.mlp.up_proj.lora_B.default.weight', 'model.layers.20.self_attn.k_proj.base_layer.weight', 'model.layers.20.self_attn.k_proj.lora_A.default.weight', 'model.layers.20.self_attn.k_proj.lora_B.default.weight', 'model.layers.20.self_attn.o_proj.base_layer.weight', 'model.layers.20.self_attn.o_proj.lora_A.default.weight', 'model.layers.20.self_attn.o_proj.lora_B.default.weight', 'model.layers.20.self_attn.q_proj.base_layer.weight', 'model.layers.20.self_attn.q_proj.lora_A.default.weight', 'model.layers.20.self_attn.q_proj.lora_B.default.weight', 'model.layers.20.self_attn.v_proj.base_layer.weight', 'model.layers.20.self_attn.v_proj.lora_A.default.weight', 'model.layers.20.self_attn.v_proj.lora_B.default.weight', 'model.layers.21.mlp.down_proj.base_layer.weight', 'model.layers.21.mlp.down_proj.lora_A.default.weight', 'model.layers.21.mlp.down_proj.lora_B.default.weight', 'model.layers.21.mlp.gate_proj.base_layer.weight', 'model.layers.21.mlp.gate_proj.lora_A.default.weight', 'model.layers.21.mlp.gate_proj.lora_B.default.weight', 'model.layers.21.mlp.up_proj.base_layer.weight', 'model.layers.21.mlp.up_proj.lora_A.default.weight', 'model.layers.21.mlp.up_proj.lora_B.default.weight', 'model.layers.21.self_attn.k_proj.base_layer.weight', 'model.layers.21.self_attn.k_proj.lora_A.default.weight', 'model.layers.21.self_attn.k_proj.lora_B.default.weight', 'model.layers.21.self_attn.o_proj.base_layer.weight', 'model.layers.21.self_attn.o_proj.lora_A.default.weight', 'model.layers.21.self_attn.o_proj.lora_B.default.weight', 'model.layers.21.self_attn.q_proj.base_layer.weight', 'model.layers.21.self_attn.q_proj.lora_A.default.weight', 'model.layers.21.self_attn.q_proj.lora_B.default.weight', 'model.layers.21.self_attn.v_proj.base_layer.weight', 'model.layers.21.self_attn.v_proj.lora_A.default.weight', 'model.layers.21.self_attn.v_proj.lora_B.default.weight', 'model.layers.22.mlp.down_proj.base_layer.weight', 'model.layers.22.mlp.down_proj.lora_A.default.weight', 'model.layers.22.mlp.down_proj.lora_B.default.weight', 'model.layers.22.mlp.gate_proj.base_layer.weight', 'model.layers.22.mlp.gate_proj.lora_A.default.weight', 'model.layers.22.mlp.gate_proj.lora_B.default.weight', 'model.layers.22.mlp.up_proj.base_layer.weight', 'model.layers.22.mlp.up_proj.lora_A.default.weight', 'model.layers.22.mlp.up_proj.lora_B.default.weight', 'model.layers.22.self_attn.k_proj.base_layer.weight', 'model.layers.22.self_attn.k_proj.lora_A.default.weight', 'model.layers.22.self_attn.k_proj.lora_B.default.weight', 'model.layers.22.self_attn.o_proj.base_layer.weight', 'model.layers.22.self_attn.o_proj.lora_A.default.weight', 'model.layers.22.self_attn.o_proj.lora_B.default.weight', 'model.layers.22.self_attn.q_proj.base_layer.weight', 'model.layers.22.self_attn.q_proj.lora_A.default.weight', 'model.layers.22.self_attn.q_proj.lora_B.default.weight', 'model.layers.22.self_attn.v_proj.base_layer.weight', 'model.layers.22.self_attn.v_proj.lora_A.default.weight', 'model.layers.22.self_attn.v_proj.lora_B.default.weight', 'model.layers.23.mlp.down_proj.base_layer.weight', 'model.layers.23.mlp.down_proj.lora_A.default.weight', 'model.layers.23.mlp.down_proj.lora_B.default.weight', 'model.layers.23.mlp.gate_proj.base_layer.weight', 'model.layers.23.mlp.gate_proj.lora_A.default.weight', 'model.layers.23.mlp.gate_proj.lora_B.default.weight', 'model.layers.23.mlp.up_proj.base_layer.weight', 'model.layers.23.mlp.up_proj.lora_A.default.weight', 'model.layers.23.mlp.up_proj.lora_B.default.weight', 'model.layers.23.self_attn.k_proj.base_layer.weight', 'model.layers.23.self_attn.k_proj.lora_A.default.weight', 'model.layers.23.self_attn.k_proj.lora_B.default.weight', 'model.layers.23.self_attn.o_proj.base_layer.weight', 'model.layers.23.self_attn.o_proj.lora_A.default.weight', 'model.layers.23.self_attn.o_proj.lora_B.default.weight', 'model.layers.23.self_attn.q_proj.base_layer.weight', 'model.layers.23.self_attn.q_proj.lora_A.default.weight', 'model.layers.23.self_attn.q_proj.lora_B.default.weight', 'model.layers.23.self_attn.v_proj.base_layer.weight', 'model.layers.23.self_attn.v_proj.lora_A.default.weight', 'model.layers.23.self_attn.v_proj.lora_B.default.weight', 'model.layers.24.mlp.down_proj.base_layer.weight', 'model.layers.24.mlp.down_proj.lora_A.default.weight', 'model.layers.24.mlp.down_proj.lora_B.default.weight', 'model.layers.24.mlp.gate_proj.base_layer.weight', 'model.layers.24.mlp.gate_proj.lora_A.default.weight', 'model.layers.24.mlp.gate_proj.lora_B.default.weight', 'model.layers.24.mlp.up_proj.base_layer.weight', 'model.layers.24.mlp.up_proj.lora_A.default.weight', 'model.layers.24.mlp.up_proj.lora_B.default.weight', 'model.layers.24.self_attn.k_proj.base_layer.weight', 'model.layers.24.self_attn.k_proj.lora_A.default.weight', 'model.layers.24.self_attn.k_proj.lora_B.default.weight', 'model.layers.24.self_attn.o_proj.base_layer.weight', 'model.layers.24.self_attn.o_proj.lora_A.default.weight', 'model.layers.24.self_attn.o_proj.lora_B.default.weight', 'model.layers.24.self_attn.q_proj.base_layer.weight', 'model.layers.24.self_attn.q_proj.lora_A.default.weight', 'model.layers.24.self_attn.q_proj.lora_B.default.weight', 'model.layers.24.self_attn.v_proj.base_layer.weight', 'model.layers.24.self_attn.v_proj.lora_A.default.weight', 'model.layers.24.self_attn.v_proj.lora_B.default.weight', 'model.layers.25.mlp.down_proj.base_layer.weight', 'model.layers.25.mlp.down_proj.lora_A.default.weight', 'model.layers.25.mlp.down_proj.lora_B.default.weight', 'model.layers.25.mlp.gate_proj.base_layer.weight', 'model.layers.25.mlp.gate_proj.lora_A.default.weight', 'model.layers.25.mlp.gate_proj.lora_B.default.weight', 'model.layers.25.mlp.up_proj.base_layer.weight', 'model.layers.25.mlp.up_proj.lora_A.default.weight', 'model.layers.25.mlp.up_proj.lora_B.default.weight', 'model.layers.25.self_attn.k_proj.base_layer.weight', 'model.layers.25.self_attn.k_proj.lora_A.default.weight', 'model.layers.25.self_attn.k_proj.lora_B.default.weight', 'model.layers.25.self_attn.o_proj.base_layer.weight', 'model.layers.25.self_attn.o_proj.lora_A.default.weight', 'model.layers.25.self_attn.o_proj.lora_B.default.weight', 'model.layers.25.self_attn.q_proj.base_layer.weight', 'model.layers.25.self_attn.q_proj.lora_A.default.weight', 'model.layers.25.self_attn.q_proj.lora_B.default.weight', 'model.layers.25.self_attn.v_proj.base_layer.weight', 'model.layers.25.self_attn.v_proj.lora_A.default.weight', 'model.layers.25.self_attn.v_proj.lora_B.default.weight', 'model.layers.26.mlp.down_proj.base_layer.weight', 'model.layers.26.mlp.down_proj.lora_A.default.weight', 'model.layers.26.mlp.down_proj.lora_B.default.weight', 'model.layers.26.mlp.gate_proj.base_layer.weight', 'model.layers.26.mlp.gate_proj.lora_A.default.weight', 'model.layers.26.mlp.gate_proj.lora_B.default.weight', 'model.layers.26.mlp.up_proj.base_layer.weight', 'model.layers.26.mlp.up_proj.lora_A.default.weight', 'model.layers.26.mlp.up_proj.lora_B.default.weight', 'model.layers.26.self_attn.k_proj.base_layer.weight', 'model.layers.26.self_attn.k_proj.lora_A.default.weight', 'model.layers.26.self_attn.k_proj.lora_B.default.weight', 'model.layers.26.self_attn.o_proj.base_layer.weight', 'model.layers.26.self_attn.o_proj.lora_A.default.weight', 'model.layers.26.self_attn.o_proj.lora_B.default.weight', 'model.layers.26.self_attn.q_proj.base_layer.weight', 'model.layers.26.self_attn.q_proj.lora_A.default.weight', 'model.layers.26.self_attn.q_proj.lora_B.default.weight', 'model.layers.26.self_attn.v_proj.base_layer.weight', 'model.layers.26.self_attn.v_proj.lora_A.default.weight', 'model.layers.26.self_attn.v_proj.lora_B.default.weight', 'model.layers.27.mlp.down_proj.base_layer.weight', 'model.layers.27.mlp.down_proj.lora_A.default.weight', 'model.layers.27.mlp.down_proj.lora_B.default.weight', 'model.layers.27.mlp.gate_proj.base_layer.weight', 'model.layers.27.mlp.gate_proj.lora_A.default.weight', 'model.layers.27.mlp.gate_proj.lora_B.default.weight', 'model.layers.27.mlp.up_proj.base_layer.weight', 'model.layers.27.mlp.up_proj.lora_A.default.weight', 'model.layers.27.mlp.up_proj.lora_B.default.weight', 'model.layers.27.self_attn.k_proj.base_layer.weight', 'model.layers.27.self_attn.k_proj.lora_A.default.weight', 'model.layers.27.self_attn.k_proj.lora_B.default.weight', 'model.layers.27.self_attn.o_proj.base_layer.weight', 'model.layers.27.self_attn.o_proj.lora_A.default.weight', 'model.layers.27.self_attn.o_proj.lora_B.default.weight', 'model.layers.27.self_attn.q_proj.base_layer.weight', 'model.layers.27.self_attn.q_proj.lora_A.default.weight', 'model.layers.27.self_attn.q_proj.lora_B.default.weight', 'model.layers.27.self_attn.v_proj.base_layer.weight', 'model.layers.27.self_attn.v_proj.lora_A.default.weight', 'model.layers.27.self_attn.v_proj.lora_B.default.weight', 'model.layers.28.mlp.down_proj.base_layer.weight', 'model.layers.28.mlp.down_proj.lora_A.default.weight', 'model.layers.28.mlp.down_proj.lora_B.default.weight', 'model.layers.28.mlp.gate_proj.base_layer.weight', 'model.layers.28.mlp.gate_proj.lora_A.default.weight', 'model.layers.28.mlp.gate_proj.lora_B.default.weight', 'model.layers.28.mlp.up_proj.base_layer.weight', 'model.layers.28.mlp.up_proj.lora_A.default.weight', 'model.layers.28.mlp.up_proj.lora_B.default.weight', 'model.layers.28.self_attn.k_proj.base_layer.weight', 'model.layers.28.self_attn.k_proj.lora_A.default.weight', 'model.layers.28.self_attn.k_proj.lora_B.default.weight', 'model.layers.28.self_attn.o_proj.base_layer.weight', 'model.layers.28.self_attn.o_proj.lora_A.default.weight', 'model.layers.28.self_attn.o_proj.lora_B.default.weight', 'model.layers.28.self_attn.q_proj.base_layer.weight', 'model.layers.28.self_attn.q_proj.lora_A.default.weight', 'model.layers.28.self_attn.q_proj.lora_B.default.weight', 'model.layers.28.self_attn.v_proj.base_layer.weight', 'model.layers.28.self_attn.v_proj.lora_A.default.weight', 'model.layers.28.self_attn.v_proj.lora_B.default.weight', 'model.layers.29.mlp.down_proj.base_layer.weight', 'model.layers.29.mlp.down_proj.lora_A.default.weight', 'model.layers.29.mlp.down_proj.lora_B.default.weight', 'model.layers.29.mlp.gate_proj.base_layer.weight', 'model.layers.29.mlp.gate_proj.lora_A.default.weight', 'model.layers.29.mlp.gate_proj.lora_B.default.weight', 'model.layers.29.mlp.up_proj.base_layer.weight', 'model.layers.29.mlp.up_proj.lora_A.default.weight', 'model.layers.29.mlp.up_proj.lora_B.default.weight', 'model.layers.29.self_attn.k_proj.base_layer.weight', 'model.layers.29.self_attn.k_proj.lora_A.default.weight', 'model.layers.29.self_attn.k_proj.lora_B.default.weight', 'model.layers.29.self_attn.o_proj.base_layer.weight', 'model.layers.29.self_attn.o_proj.lora_A.default.weight', 'model.layers.29.self_attn.o_proj.lora_B.default.weight', 'model.layers.29.self_attn.q_proj.base_layer.weight', 'model.layers.29.self_attn.q_proj.lora_A.default.weight', 'model.layers.29.self_attn.q_proj.lora_B.default.weight', 'model.layers.29.self_attn.v_proj.base_layer.weight', 'model.layers.29.self_attn.v_proj.lora_A.default.weight', 'model.layers.29.self_attn.v_proj.lora_B.default.weight', 'model.layers.3.mlp.down_proj.base_layer.weight', 'model.layers.3.mlp.down_proj.lora_A.default.weight', 'model.layers.3.mlp.down_proj.lora_B.default.weight', 'model.layers.3.mlp.gate_proj.base_layer.weight', 'model.layers.3.mlp.gate_proj.lora_A.default.weight', 'model.layers.3.mlp.gate_proj.lora_B.default.weight', 'model.layers.3.mlp.up_proj.base_layer.weight', 'model.layers.3.mlp.up_proj.lora_A.default.weight', 'model.layers.3.mlp.up_proj.lora_B.default.weight', 'model.layers.3.self_attn.k_proj.base_layer.weight', 'model.layers.3.self_attn.k_proj.lora_A.default.weight', 'model.layers.3.self_attn.k_proj.lora_B.default.weight', 'model.layers.3.self_attn.o_proj.base_layer.weight', 'model.layers.3.self_attn.o_proj.lora_A.default.weight', 'model.layers.3.self_attn.o_proj.lora_B.default.weight', 'model.layers.3.self_attn.q_proj.base_layer.weight', 'model.layers.3.self_attn.q_proj.lora_A.default.weight', 'model.layers.3.self_attn.q_proj.lora_B.default.weight', 'model.layers.3.self_attn.v_proj.base_layer.weight', 'model.layers.3.self_attn.v_proj.lora_A.default.weight', 'model.layers.3.self_attn.v_proj.lora_B.default.weight', 'model.layers.30.mlp.down_proj.base_layer.weight', 'model.layers.30.mlp.down_proj.lora_A.default.weight', 'model.layers.30.mlp.down_proj.lora_B.default.weight', 'model.layers.30.mlp.gate_proj.base_layer.weight', 'model.layers.30.mlp.gate_proj.lora_A.default.weight', 'model.layers.30.mlp.gate_proj.lora_B.default.weight', 'model.layers.30.mlp.up_proj.base_layer.weight', 'model.layers.30.mlp.up_proj.lora_A.default.weight', 'model.layers.30.mlp.up_proj.lora_B.default.weight', 'model.layers.30.self_attn.k_proj.base_layer.weight', 'model.layers.30.self_attn.k_proj.lora_A.default.weight', 'model.layers.30.self_attn.k_proj.lora_B.default.weight', 'model.layers.30.self_attn.o_proj.base_layer.weight', 'model.layers.30.self_attn.o_proj.lora_A.default.weight', 'model.layers.30.self_attn.o_proj.lora_B.default.weight', 'model.layers.30.self_attn.q_proj.base_layer.weight', 'model.layers.30.self_attn.q_proj.lora_A.default.weight', 'model.layers.30.self_attn.q_proj.lora_B.default.weight', 'model.layers.30.self_attn.v_proj.base_layer.weight', 'model.layers.30.self_attn.v_proj.lora_A.default.weight', 'model.layers.30.self_attn.v_proj.lora_B.default.weight', 'model.layers.31.mlp.down_proj.base_layer.weight', 'model.layers.31.mlp.down_proj.lora_A.default.weight', 'model.layers.31.mlp.down_proj.lora_B.default.weight', 'model.layers.31.mlp.gate_proj.base_layer.weight', 'model.layers.31.mlp.gate_proj.lora_A.default.weight', 'model.layers.31.mlp.gate_proj.lora_B.default.weight', 'model.layers.31.mlp.up_proj.base_layer.weight', 'model.layers.31.mlp.up_proj.lora_A.default.weight', 'model.layers.31.mlp.up_proj.lora_B.default.weight', 'model.layers.31.self_attn.k_proj.base_layer.weight', 'model.layers.31.self_attn.k_proj.lora_A.default.weight', 'model.layers.31.self_attn.k_proj.lora_B.default.weight', 'model.layers.31.self_attn.o_proj.base_layer.weight', 'model.layers.31.self_attn.o_proj.lora_A.default.weight', 'model.layers.31.self_attn.o_proj.lora_B.default.weight', 'model.layers.31.self_attn.q_proj.base_layer.weight', 'model.layers.31.self_attn.q_proj.lora_A.default.weight', 'model.layers.31.self_attn.q_proj.lora_B.default.weight', 'model.layers.31.self_attn.v_proj.base_layer.weight', 'model.layers.31.self_attn.v_proj.lora_A.default.weight', 'model.layers.31.self_attn.v_proj.lora_B.default.weight', 'model.layers.32.mlp.down_proj.base_layer.weight', 'model.layers.32.mlp.down_proj.lora_A.default.weight', 'model.layers.32.mlp.down_proj.lora_B.default.weight', 'model.layers.32.mlp.gate_proj.base_layer.weight', 'model.layers.32.mlp.gate_proj.lora_A.default.weight', 'model.layers.32.mlp.gate_proj.lora_B.default.weight', 'model.layers.32.mlp.up_proj.base_layer.weight', 'model.layers.32.mlp.up_proj.lora_A.default.weight', 'model.layers.32.mlp.up_proj.lora_B.default.weight', 'model.layers.32.self_attn.k_proj.base_layer.weight', 'model.layers.32.self_attn.k_proj.lora_A.default.weight', 'model.layers.32.self_attn.k_proj.lora_B.default.weight', 'model.layers.32.self_attn.o_proj.base_layer.weight', 'model.layers.32.self_attn.o_proj.lora_A.default.weight', 'model.layers.32.self_attn.o_proj.lora_B.default.weight', 'model.layers.32.self_attn.q_proj.base_layer.weight', 'model.layers.32.self_attn.q_proj.lora_A.default.weight', 'model.layers.32.self_attn.q_proj.lora_B.default.weight', 'model.layers.32.self_attn.v_proj.base_layer.weight', 'model.layers.32.self_attn.v_proj.lora_A.default.weight', 'model.layers.32.self_attn.v_proj.lora_B.default.weight', 'model.layers.33.mlp.down_proj.base_layer.weight', 'model.layers.33.mlp.down_proj.lora_A.default.weight', 'model.layers.33.mlp.down_proj.lora_B.default.weight', 'model.layers.33.mlp.gate_proj.base_layer.weight', 'model.layers.33.mlp.gate_proj.lora_A.default.weight', 'model.layers.33.mlp.gate_proj.lora_B.default.weight', 'model.layers.33.mlp.up_proj.base_layer.weight', 'model.layers.33.mlp.up_proj.lora_A.default.weight', 'model.layers.33.mlp.up_proj.lora_B.default.weight', 'model.layers.33.self_attn.k_proj.base_layer.weight', 'model.layers.33.self_attn.k_proj.lora_A.default.weight', 'model.layers.33.self_attn.k_proj.lora_B.default.weight', 'model.layers.33.self_attn.o_proj.base_layer.weight', 'model.layers.33.self_attn.o_proj.lora_A.default.weight', 'model.layers.33.self_attn.o_proj.lora_B.default.weight', 'model.layers.33.self_attn.q_proj.base_layer.weight', 'model.layers.33.self_attn.q_proj.lora_A.default.weight', 'model.layers.33.self_attn.q_proj.lora_B.default.weight', 'model.layers.33.self_attn.v_proj.base_layer.weight', 'model.layers.33.self_attn.v_proj.lora_A.default.weight', 'model.layers.33.self_attn.v_proj.lora_B.default.weight', 'model.layers.34.mlp.down_proj.base_layer.weight', 'model.layers.34.mlp.down_proj.lora_A.default.weight', 'model.layers.34.mlp.down_proj.lora_B.default.weight', 'model.layers.34.mlp.gate_proj.base_layer.weight', 'model.layers.34.mlp.gate_proj.lora_A.default.weight', 'model.layers.34.mlp.gate_proj.lora_B.default.weight', 'model.layers.34.mlp.up_proj.base_layer.weight', 'model.layers.34.mlp.up_proj.lora_A.default.weight', 'model.layers.34.mlp.up_proj.lora_B.default.weight', 'model.layers.34.self_attn.k_proj.base_layer.weight', 'model.layers.34.self_attn.k_proj.lora_A.default.weight', 'model.layers.34.self_attn.k_proj.lora_B.default.weight', 'model.layers.34.self_attn.o_proj.base_layer.weight', 'model.layers.34.self_attn.o_proj.lora_A.default.weight', 'model.layers.34.self_attn.o_proj.lora_B.default.weight', 'model.layers.34.self_attn.q_proj.base_layer.weight', 'model.layers.34.self_attn.q_proj.lora_A.default.weight', 'model.layers.34.self_attn.q_proj.lora_B.default.weight', 'model.layers.34.self_attn.v_proj.base_layer.weight', 'model.layers.34.self_attn.v_proj.lora_A.default.weight', 'model.layers.34.self_attn.v_proj.lora_B.default.weight', 'model.layers.35.mlp.down_proj.base_layer.weight', 'model.layers.35.mlp.down_proj.lora_A.default.weight', 'model.layers.35.mlp.down_proj.lora_B.default.weight', 'model.layers.35.mlp.gate_proj.base_layer.weight', 'model.layers.35.mlp.gate_proj.lora_A.default.weight', 'model.layers.35.mlp.gate_proj.lora_B.default.weight', 'model.layers.35.mlp.up_proj.base_layer.weight', 'model.layers.35.mlp.up_proj.lora_A.default.weight', 'model.layers.35.mlp.up_proj.lora_B.default.weight', 'model.layers.35.self_attn.k_proj.base_layer.weight', 'model.layers.35.self_attn.k_proj.lora_A.default.weight', 'model.layers.35.self_attn.k_proj.lora_B.default.weight', 'model.layers.35.self_attn.o_proj.base_layer.weight', 'model.layers.35.self_attn.o_proj.lora_A.default.weight', 'model.layers.35.self_attn.o_proj.lora_B.default.weight', 'model.layers.35.self_attn.q_proj.base_layer.weight', 'model.layers.35.self_attn.q_proj.lora_A.default.weight', 'model.layers.35.self_attn.q_proj.lora_B.default.weight', 'model.layers.35.self_attn.v_proj.base_layer.weight', 'model.layers.35.self_attn.v_proj.lora_A.default.weight', 'model.layers.35.self_attn.v_proj.lora_B.default.weight', 'model.layers.36.mlp.down_proj.base_layer.weight', 'model.layers.36.mlp.down_proj.lora_A.default.weight', 'model.layers.36.mlp.down_proj.lora_B.default.weight', 'model.layers.36.mlp.gate_proj.base_layer.weight', 'model.layers.36.mlp.gate_proj.lora_A.default.weight', 'model.layers.36.mlp.gate_proj.lora_B.default.weight', 'model.layers.36.mlp.up_proj.base_layer.weight', 'model.layers.36.mlp.up_proj.lora_A.default.weight', 'model.layers.36.mlp.up_proj.lora_B.default.weight', 'model.layers.36.self_attn.k_proj.base_layer.weight', 'model.layers.36.self_attn.k_proj.lora_A.default.weight', 'model.layers.36.self_attn.k_proj.lora_B.default.weight', 'model.layers.36.self_attn.o_proj.base_layer.weight', 'model.layers.36.self_attn.o_proj.lora_A.default.weight', 'model.layers.36.self_attn.o_proj.lora_B.default.weight', 'model.layers.36.self_attn.q_proj.base_layer.weight', 'model.layers.36.self_attn.q_proj.lora_A.default.weight', 'model.layers.36.self_attn.q_proj.lora_B.default.weight', 'model.layers.36.self_attn.v_proj.base_layer.weight', 'model.layers.36.self_attn.v_proj.lora_A.default.weight', 'model.layers.36.self_attn.v_proj.lora_B.default.weight', 'model.layers.37.mlp.down_proj.base_layer.weight', 'model.layers.37.mlp.down_proj.lora_A.default.weight', 'model.layers.37.mlp.down_proj.lora_B.default.weight', 'model.layers.37.mlp.gate_proj.base_layer.weight', 'model.layers.37.mlp.gate_proj.lora_A.default.weight', 'model.layers.37.mlp.gate_proj.lora_B.default.weight', 'model.layers.37.mlp.up_proj.base_layer.weight', 'model.layers.37.mlp.up_proj.lora_A.default.weight', 'model.layers.37.mlp.up_proj.lora_B.default.weight', 'model.layers.37.self_attn.k_proj.base_layer.weight', 'model.layers.37.self_attn.k_proj.lora_A.default.weight', 'model.layers.37.self_attn.k_proj.lora_B.default.weight', 'model.layers.37.self_attn.o_proj.base_layer.weight', 'model.layers.37.self_attn.o_proj.lora_A.default.weight', 'model.layers.37.self_attn.o_proj.lora_B.default.weight', 'model.layers.37.self_attn.q_proj.base_layer.weight', 'model.layers.37.self_attn.q_proj.lora_A.default.weight', 'model.layers.37.self_attn.q_proj.lora_B.default.weight', 'model.layers.37.self_attn.v_proj.base_layer.weight', 'model.layers.37.self_attn.v_proj.lora_A.default.weight', 'model.layers.37.self_attn.v_proj.lora_B.default.weight', 'model.layers.38.mlp.down_proj.base_layer.weight', 'model.layers.38.mlp.down_proj.lora_A.default.weight', 'model.layers.38.mlp.down_proj.lora_B.default.weight', 'model.layers.38.mlp.gate_proj.base_layer.weight', 'model.layers.38.mlp.gate_proj.lora_A.default.weight', 'model.layers.38.mlp.gate_proj.lora_B.default.weight', 'model.layers.38.mlp.up_proj.base_layer.weight', 'model.layers.38.mlp.up_proj.lora_A.default.weight', 'model.layers.38.mlp.up_proj.lora_B.default.weight', 'model.layers.38.self_attn.k_proj.base_layer.weight', 'model.layers.38.self_attn.k_proj.lora_A.default.weight', 'model.layers.38.self_attn.k_proj.lora_B.default.weight', 'model.layers.38.self_attn.o_proj.base_layer.weight', 'model.layers.38.self_attn.o_proj.lora_A.default.weight', 'model.layers.38.self_attn.o_proj.lora_B.default.weight', 'model.layers.38.self_attn.q_proj.base_layer.weight', 'model.layers.38.self_attn.q_proj.lora_A.default.weight', 'model.layers.38.self_attn.q_proj.lora_B.default.weight', 'model.layers.38.self_attn.v_proj.base_layer.weight', 'model.layers.38.self_attn.v_proj.lora_A.default.weight', 'model.layers.38.self_attn.v_proj.lora_B.default.weight', 'model.layers.39.mlp.down_proj.base_layer.weight', 'model.layers.39.mlp.down_proj.lora_A.default.weight', 'model.layers.39.mlp.down_proj.lora_B.default.weight', 'model.layers.39.mlp.gate_proj.base_layer.weight', 'model.layers.39.mlp.gate_proj.lora_A.default.weight', 'model.layers.39.mlp.gate_proj.lora_B.default.weight', 'model.layers.39.mlp.up_proj.base_layer.weight', 'model.layers.39.mlp.up_proj.lora_A.default.weight', 'model.layers.39.mlp.up_proj.lora_B.default.weight', 'model.layers.39.self_attn.k_proj.base_layer.weight', 'model.layers.39.self_attn.k_proj.lora_A.default.weight', 'model.layers.39.self_attn.k_proj.lora_B.default.weight', 'model.layers.39.self_attn.o_proj.base_layer.weight', 'model.layers.39.self_attn.o_proj.lora_A.default.weight', 'model.layers.39.self_attn.o_proj.lora_B.default.weight', 'model.layers.39.self_attn.q_proj.base_layer.weight', 'model.layers.39.self_attn.q_proj.lora_A.default.weight', 'model.layers.39.self_attn.q_proj.lora_B.default.weight', 'model.layers.39.self_attn.v_proj.base_layer.weight', 'model.layers.39.self_attn.v_proj.lora_A.default.weight', 'model.layers.39.self_attn.v_proj.lora_B.default.weight', 'model.layers.4.mlp.down_proj.base_layer.weight', 'model.layers.4.mlp.down_proj.lora_A.default.weight', 'model.layers.4.mlp.down_proj.lora_B.default.weight', 'model.layers.4.mlp.gate_proj.base_layer.weight', 'model.layers.4.mlp.gate_proj.lora_A.default.weight', 'model.layers.4.mlp.gate_proj.lora_B.default.weight', 'model.layers.4.mlp.up_proj.base_layer.weight', 'model.layers.4.mlp.up_proj.lora_A.default.weight', 'model.layers.4.mlp.up_proj.lora_B.default.weight', 'model.layers.4.self_attn.k_proj.base_layer.weight', 'model.layers.4.self_attn.k_proj.lora_A.default.weight', 'model.layers.4.self_attn.k_proj.lora_B.default.weight', 'model.layers.4.self_attn.o_proj.base_layer.weight', 'model.layers.4.self_attn.o_proj.lora_A.default.weight', 'model.layers.4.self_attn.o_proj.lora_B.default.weight', 'model.layers.4.self_attn.q_proj.base_layer.weight', 'model.layers.4.self_attn.q_proj.lora_A.default.weight', 'model.layers.4.self_attn.q_proj.lora_B.default.weight', 'model.layers.4.self_attn.v_proj.base_layer.weight', 'model.layers.4.self_attn.v_proj.lora_A.default.weight', 'model.layers.4.self_attn.v_proj.lora_B.default.weight', 'model.layers.5.mlp.down_proj.base_layer.weight', 'model.layers.5.mlp.down_proj.lora_A.default.weight', 'model.layers.5.mlp.down_proj.lora_B.default.weight', 'model.layers.5.mlp.gate_proj.base_layer.weight', 'model.layers.5.mlp.gate_proj.lora_A.default.weight', 'model.layers.5.mlp.gate_proj.lora_B.default.weight', 'model.layers.5.mlp.up_proj.base_layer.weight', 'model.layers.5.mlp.up_proj.lora_A.default.weight', 'model.layers.5.mlp.up_proj.lora_B.default.weight', 'model.layers.5.self_attn.k_proj.base_layer.weight', 'model.layers.5.self_attn.k_proj.lora_A.default.weight', 'model.layers.5.self_attn.k_proj.lora_B.default.weight', 'model.layers.5.self_attn.o_proj.base_layer.weight', 'model.layers.5.self_attn.o_proj.lora_A.default.weight', 'model.layers.5.self_attn.o_proj.lora_B.default.weight', 'model.layers.5.self_attn.q_proj.base_layer.weight', 'model.layers.5.self_attn.q_proj.lora_A.default.weight', 'model.layers.5.self_attn.q_proj.lora_B.default.weight', 'model.layers.5.self_attn.v_proj.base_layer.weight', 'model.layers.5.self_attn.v_proj.lora_A.default.weight', 'model.layers.5.self_attn.v_proj.lora_B.default.weight', 'model.layers.6.mlp.down_proj.base_layer.weight', 'model.layers.6.mlp.down_proj.lora_A.default.weight', 'model.layers.6.mlp.down_proj.lora_B.default.weight', 'model.layers.6.mlp.gate_proj.base_layer.weight', 'model.layers.6.mlp.gate_proj.lora_A.default.weight', 'model.layers.6.mlp.gate_proj.lora_B.default.weight', 'model.layers.6.mlp.up_proj.base_layer.weight', 'model.layers.6.mlp.up_proj.lora_A.default.weight', 'model.layers.6.mlp.up_proj.lora_B.default.weight', 'model.layers.6.self_attn.k_proj.base_layer.weight', 'model.layers.6.self_attn.k_proj.lora_A.default.weight', 'model.layers.6.self_attn.k_proj.lora_B.default.weight', 'model.layers.6.self_attn.o_proj.base_layer.weight', 'model.layers.6.self_attn.o_proj.lora_A.default.weight', 'model.layers.6.self_attn.o_proj.lora_B.default.weight', 'model.layers.6.self_attn.q_proj.base_layer.weight', 'model.layers.6.self_attn.q_proj.lora_A.default.weight', 'model.layers.6.self_attn.q_proj.lora_B.default.weight', 'model.layers.6.self_attn.v_proj.base_layer.weight', 'model.layers.6.self_attn.v_proj.lora_A.default.weight', 'model.layers.6.self_attn.v_proj.lora_B.default.weight', 'model.layers.7.mlp.down_proj.base_layer.weight', 'model.layers.7.mlp.down_proj.lora_A.default.weight', 'model.layers.7.mlp.down_proj.lora_B.default.weight', 'model.layers.7.mlp.gate_proj.base_layer.weight', 'model.layers.7.mlp.gate_proj.lora_A.default.weight', 'model.layers.7.mlp.gate_proj.lora_B.default.weight', 'model.layers.7.mlp.up_proj.base_layer.weight', 'model.layers.7.mlp.up_proj.lora_A.default.weight', 'model.layers.7.mlp.up_proj.lora_B.default.weight', 'model.layers.7.self_attn.k_proj.base_layer.weight', 'model.layers.7.self_attn.k_proj.lora_A.default.weight', 'model.layers.7.self_attn.k_proj.lora_B.default.weight', 'model.layers.7.self_attn.o_proj.base_layer.weight', 'model.layers.7.self_attn.o_proj.lora_A.default.weight', 'model.layers.7.self_attn.o_proj.lora_B.default.weight', 'model.layers.7.self_attn.q_proj.base_layer.weight', 'model.layers.7.self_attn.q_proj.lora_A.default.weight', 'model.layers.7.self_attn.q_proj.lora_B.default.weight', 'model.layers.7.self_attn.v_proj.base_layer.weight', 'model.layers.7.self_attn.v_proj.lora_A.default.weight', 'model.layers.7.self_attn.v_proj.lora_B.default.weight', 'model.layers.8.mlp.down_proj.base_layer.weight', 'model.layers.8.mlp.down_proj.lora_A.default.weight', 'model.layers.8.mlp.down_proj.lora_B.default.weight', 'model.layers.8.mlp.gate_proj.base_layer.weight', 'model.layers.8.mlp.gate_proj.lora_A.default.weight', 'model.layers.8.mlp.gate_proj.lora_B.default.weight', 'model.layers.8.mlp.up_proj.base_layer.weight', 'model.layers.8.mlp.up_proj.lora_A.default.weight', 'model.layers.8.mlp.up_proj.lora_B.default.weight', 'model.layers.8.self_attn.k_proj.base_layer.weight', 'model.layers.8.self_attn.k_proj.lora_A.default.weight', 'model.layers.8.self_attn.k_proj.lora_B.default.weight', 'model.layers.8.self_attn.o_proj.base_layer.weight', 'model.layers.8.self_attn.o_proj.lora_A.default.weight', 'model.layers.8.self_attn.o_proj.lora_B.default.weight', 'model.layers.8.self_attn.q_proj.base_layer.weight', 'model.layers.8.self_attn.q_proj.lora_A.default.weight', 'model.layers.8.self_attn.q_proj.lora_B.default.weight', 'model.layers.8.self_attn.v_proj.base_layer.weight', 'model.layers.8.self_attn.v_proj.lora_A.default.weight', 'model.layers.8.self_attn.v_proj.lora_B.default.weight', 'model.layers.9.mlp.down_proj.base_layer.weight', 'model.layers.9.mlp.down_proj.lora_A.default.weight', 'model.layers.9.mlp.down_proj.lora_B.default.weight', 'model.layers.9.mlp.gate_proj.base_layer.weight', 'model.layers.9.mlp.gate_proj.lora_A.default.weight', 'model.layers.9.mlp.gate_proj.lora_B.default.weight', 'model.layers.9.mlp.up_proj.base_layer.weight', 'model.layers.9.mlp.up_proj.lora_A.default.weight', 'model.layers.9.mlp.up_proj.lora_B.default.weight', 'model.layers.9.self_attn.k_proj.base_layer.weight', 'model.layers.9.self_attn.k_proj.lora_A.default.weight', 'model.layers.9.self_attn.k_proj.lora_B.default.weight', 'model.layers.9.self_attn.o_proj.base_layer.weight', 'model.layers.9.self_attn.o_proj.lora_A.default.weight', 'model.layers.9.self_attn.o_proj.lora_B.default.weight', 'model.layers.9.self_attn.q_proj.base_layer.weight', 'model.layers.9.self_attn.q_proj.lora_A.default.weight', 'model.layers.9.self_attn.q_proj.lora_B.default.weight', 'model.layers.9.self_attn.v_proj.base_layer.weight', 'model.layers.9.self_attn.v_proj.lora_A.default.weight', 'model.layers.9.self_attn.v_proj.lora_B.default.weight']\n",
      "- This IS expected if you are initializing LlamaForCausalLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing LlamaForCausalLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of LlamaForCausalLM were not initialized from the model checkpoint at BanglaLLM/bangla-llama-13b-instruct-v0.1 and are newly initialized: ['model.layers.0.mlp.down_proj.weight', 'model.layers.0.mlp.gate_proj.weight', 'model.layers.0.mlp.up_proj.weight', 'model.layers.0.self_attn.k_proj.weight', 'model.layers.0.self_attn.o_proj.weight', 'model.layers.0.self_attn.q_proj.weight', 'model.layers.0.self_attn.v_proj.weight', 'model.layers.1.mlp.down_proj.weight', 'model.layers.1.mlp.gate_proj.weight', 'model.layers.1.mlp.up_proj.weight', 'model.layers.1.self_attn.k_proj.weight', 'model.layers.1.self_attn.o_proj.weight', 'model.layers.1.self_attn.q_proj.weight', 'model.layers.1.self_attn.v_proj.weight', 'model.layers.10.mlp.down_proj.weight', 'model.layers.10.mlp.gate_proj.weight', 'model.layers.10.mlp.up_proj.weight', 'model.layers.10.self_attn.k_proj.weight', 'model.layers.10.self_attn.o_proj.weight', 'model.layers.10.self_attn.q_proj.weight', 'model.layers.10.self_attn.v_proj.weight', 'model.layers.11.mlp.down_proj.weight', 'model.layers.11.mlp.gate_proj.weight', 'model.layers.11.mlp.up_proj.weight', 'model.layers.11.self_attn.k_proj.weight', 'model.layers.11.self_attn.o_proj.weight', 'model.layers.11.self_attn.q_proj.weight', 'model.layers.11.self_attn.v_proj.weight', 'model.layers.12.mlp.down_proj.weight', 'model.layers.12.mlp.gate_proj.weight', 'model.layers.12.mlp.up_proj.weight', 'model.layers.12.self_attn.k_proj.weight', 'model.layers.12.self_attn.o_proj.weight', 'model.layers.12.self_attn.q_proj.weight', 'model.layers.12.self_attn.v_proj.weight', 'model.layers.13.mlp.down_proj.weight', 'model.layers.13.mlp.gate_proj.weight', 'model.layers.13.mlp.up_proj.weight', 'model.layers.13.self_attn.k_proj.weight', 'model.layers.13.self_attn.o_proj.weight', 'model.layers.13.self_attn.q_proj.weight', 'model.layers.13.self_attn.v_proj.weight', 'model.layers.14.mlp.down_proj.weight', 'model.layers.14.mlp.gate_proj.weight', 'model.layers.14.mlp.up_proj.weight', 'model.layers.14.self_attn.k_proj.weight', 'model.layers.14.self_attn.o_proj.weight', 'model.layers.14.self_attn.q_proj.weight', 'model.layers.14.self_attn.v_proj.weight', 'model.layers.15.mlp.down_proj.weight', 'model.layers.15.mlp.gate_proj.weight', 'model.layers.15.mlp.up_proj.weight', 'model.layers.15.self_attn.k_proj.weight', 'model.layers.15.self_attn.o_proj.weight', 'model.layers.15.self_attn.q_proj.weight', 'model.layers.15.self_attn.v_proj.weight', 'model.layers.16.mlp.down_proj.weight', 'model.layers.16.mlp.gate_proj.weight', 'model.layers.16.mlp.up_proj.weight', 'model.layers.16.self_attn.k_proj.weight', 'model.layers.16.self_attn.o_proj.weight', 'model.layers.16.self_attn.q_proj.weight', 'model.layers.16.self_attn.v_proj.weight', 'model.layers.17.mlp.down_proj.weight', 'model.layers.17.mlp.gate_proj.weight', 'model.layers.17.mlp.up_proj.weight', 'model.layers.17.self_attn.k_proj.weight', 'model.layers.17.self_attn.o_proj.weight', 'model.layers.17.self_attn.q_proj.weight', 'model.layers.17.self_attn.v_proj.weight', 'model.layers.18.mlp.down_proj.weight', 'model.layers.18.mlp.gate_proj.weight', 'model.layers.18.mlp.up_proj.weight', 'model.layers.18.self_attn.k_proj.weight', 'model.layers.18.self_attn.o_proj.weight', 'model.layers.18.self_attn.q_proj.weight', 'model.layers.18.self_attn.v_proj.weight', 'model.layers.19.mlp.down_proj.weight', 'model.layers.19.mlp.gate_proj.weight', 'model.layers.19.mlp.up_proj.weight', 'model.layers.19.self_attn.k_proj.weight', 'model.layers.19.self_attn.o_proj.weight', 'model.layers.19.self_attn.q_proj.weight', 'model.layers.19.self_attn.v_proj.weight', 'model.layers.2.mlp.down_proj.weight', 'model.layers.2.mlp.gate_proj.weight', 'model.layers.2.mlp.up_proj.weight', 'model.layers.2.self_attn.k_proj.weight', 'model.layers.2.self_attn.o_proj.weight', 'model.layers.2.self_attn.q_proj.weight', 'model.layers.2.self_attn.v_proj.weight', 'model.layers.20.mlp.down_proj.weight', 'model.layers.20.mlp.gate_proj.weight', 'model.layers.20.mlp.up_proj.weight', 'model.layers.20.self_attn.k_proj.weight', 'model.layers.20.self_attn.o_proj.weight', 'model.layers.20.self_attn.q_proj.weight', 'model.layers.20.self_attn.v_proj.weight', 'model.layers.21.mlp.down_proj.weight', 'model.layers.21.mlp.gate_proj.weight', 'model.layers.21.mlp.up_proj.weight', 'model.layers.21.self_attn.k_proj.weight', 'model.layers.21.self_attn.o_proj.weight', 'model.layers.21.self_attn.q_proj.weight', 'model.layers.21.self_attn.v_proj.weight', 'model.layers.22.mlp.down_proj.weight', 'model.layers.22.mlp.gate_proj.weight', 'model.layers.22.mlp.up_proj.weight', 'model.layers.22.self_attn.k_proj.weight', 'model.layers.22.self_attn.o_proj.weight', 'model.layers.22.self_attn.q_proj.weight', 'model.layers.22.self_attn.v_proj.weight', 'model.layers.23.mlp.down_proj.weight', 'model.layers.23.mlp.gate_proj.weight', 'model.layers.23.mlp.up_proj.weight', 'model.layers.23.self_attn.k_proj.weight', 'model.layers.23.self_attn.o_proj.weight', 'model.layers.23.self_attn.q_proj.weight', 'model.layers.23.self_attn.v_proj.weight', 'model.layers.24.mlp.down_proj.weight', 'model.layers.24.mlp.gate_proj.weight', 'model.layers.24.mlp.up_proj.weight', 'model.layers.24.self_attn.k_proj.weight', 'model.layers.24.self_attn.o_proj.weight', 'model.layers.24.self_attn.q_proj.weight', 'model.layers.24.self_attn.v_proj.weight', 'model.layers.25.mlp.down_proj.weight', 'model.layers.25.mlp.gate_proj.weight', 'model.layers.25.mlp.up_proj.weight', 'model.layers.25.self_attn.k_proj.weight', 'model.layers.25.self_attn.o_proj.weight', 'model.layers.25.self_attn.q_proj.weight', 'model.layers.25.self_attn.v_proj.weight', 'model.layers.26.mlp.down_proj.weight', 'model.layers.26.mlp.gate_proj.weight', 'model.layers.26.mlp.up_proj.weight', 'model.layers.26.self_attn.k_proj.weight', 'model.layers.26.self_attn.o_proj.weight', 'model.layers.26.self_attn.q_proj.weight', 'model.layers.26.self_attn.v_proj.weight', 'model.layers.27.mlp.down_proj.weight', 'model.layers.27.mlp.gate_proj.weight', 'model.layers.27.mlp.up_proj.weight', 'model.layers.27.self_attn.k_proj.weight', 'model.layers.27.self_attn.o_proj.weight', 'model.layers.27.self_attn.q_proj.weight', 'model.layers.27.self_attn.v_proj.weight', 'model.layers.28.mlp.down_proj.weight', 'model.layers.28.mlp.gate_proj.weight', 'model.layers.28.mlp.up_proj.weight', 'model.layers.28.self_attn.k_proj.weight', 'model.layers.28.self_attn.o_proj.weight', 'model.layers.28.self_attn.q_proj.weight', 'model.layers.28.self_attn.v_proj.weight', 'model.layers.29.mlp.down_proj.weight', 'model.layers.29.mlp.gate_proj.weight', 'model.layers.29.mlp.up_proj.weight', 'model.layers.29.self_attn.k_proj.weight', 'model.layers.29.self_attn.o_proj.weight', 'model.layers.29.self_attn.q_proj.weight', 'model.layers.29.self_attn.v_proj.weight', 'model.layers.3.mlp.down_proj.weight', 'model.layers.3.mlp.gate_proj.weight', 'model.layers.3.mlp.up_proj.weight', 'model.layers.3.self_attn.k_proj.weight', 'model.layers.3.self_attn.o_proj.weight', 'model.layers.3.self_attn.q_proj.weight', 'model.layers.3.self_attn.v_proj.weight', 'model.layers.30.mlp.down_proj.weight', 'model.layers.30.mlp.gate_proj.weight', 'model.layers.30.mlp.up_proj.weight', 'model.layers.30.self_attn.k_proj.weight', 'model.layers.30.self_attn.o_proj.weight', 'model.layers.30.self_attn.q_proj.weight', 'model.layers.30.self_attn.v_proj.weight', 'model.layers.31.mlp.down_proj.weight', 'model.layers.31.mlp.gate_proj.weight', 'model.layers.31.mlp.up_proj.weight', 'model.layers.31.self_attn.k_proj.weight', 'model.layers.31.self_attn.o_proj.weight', 'model.layers.31.self_attn.q_proj.weight', 'model.layers.31.self_attn.v_proj.weight', 'model.layers.32.mlp.down_proj.weight', 'model.layers.32.mlp.gate_proj.weight', 'model.layers.32.mlp.up_proj.weight', 'model.layers.32.self_attn.k_proj.weight', 'model.layers.32.self_attn.o_proj.weight', 'model.layers.32.self_attn.q_proj.weight', 'model.layers.32.self_attn.v_proj.weight', 'model.layers.33.mlp.down_proj.weight', 'model.layers.33.mlp.gate_proj.weight', 'model.layers.33.mlp.up_proj.weight', 'model.layers.33.self_attn.k_proj.weight', 'model.layers.33.self_attn.o_proj.weight', 'model.layers.33.self_attn.q_proj.weight', 'model.layers.33.self_attn.v_proj.weight', 'model.layers.34.mlp.down_proj.weight', 'model.layers.34.mlp.gate_proj.weight', 'model.layers.34.mlp.up_proj.weight', 'model.layers.34.self_attn.k_proj.weight', 'model.layers.34.self_attn.o_proj.weight', 'model.layers.34.self_attn.q_proj.weight', 'model.layers.34.self_attn.v_proj.weight', 'model.layers.35.mlp.down_proj.weight', 'model.layers.35.mlp.gate_proj.weight', 'model.layers.35.mlp.up_proj.weight', 'model.layers.35.self_attn.k_proj.weight', 'model.layers.35.self_attn.o_proj.weight', 'model.layers.35.self_attn.q_proj.weight', 'model.layers.35.self_attn.v_proj.weight', 'model.layers.36.mlp.down_proj.weight', 'model.layers.36.mlp.gate_proj.weight', 'model.layers.36.mlp.up_proj.weight', 'model.layers.36.self_attn.k_proj.weight', 'model.layers.36.self_attn.o_proj.weight', 'model.layers.36.self_attn.q_proj.weight', 'model.layers.36.self_attn.v_proj.weight', 'model.layers.37.mlp.down_proj.weight', 'model.layers.37.mlp.gate_proj.weight', 'model.layers.37.mlp.up_proj.weight', 'model.layers.37.self_attn.k_proj.weight', 'model.layers.37.self_attn.o_proj.weight', 'model.layers.37.self_attn.q_proj.weight', 'model.layers.37.self_attn.v_proj.weight', 'model.layers.38.mlp.down_proj.weight', 'model.layers.38.mlp.gate_proj.weight', 'model.layers.38.mlp.up_proj.weight', 'model.layers.38.self_attn.k_proj.weight', 'model.layers.38.self_attn.o_proj.weight', 'model.layers.38.self_attn.q_proj.weight', 'model.layers.38.self_attn.v_proj.weight', 'model.layers.39.mlp.down_proj.weight', 'model.layers.39.mlp.gate_proj.weight', 'model.layers.39.mlp.up_proj.weight', 'model.layers.39.self_attn.k_proj.weight', 'model.layers.39.self_attn.o_proj.weight', 'model.layers.39.self_attn.q_proj.weight', 'model.layers.39.self_attn.v_proj.weight', 'model.layers.4.mlp.down_proj.weight', 'model.layers.4.mlp.gate_proj.weight', 'model.layers.4.mlp.up_proj.weight', 'model.layers.4.self_attn.k_proj.weight', 'model.layers.4.self_attn.o_proj.weight', 'model.layers.4.self_attn.q_proj.weight', 'model.layers.4.self_attn.v_proj.weight', 'model.layers.5.mlp.down_proj.weight', 'model.layers.5.mlp.gate_proj.weight', 'model.layers.5.mlp.up_proj.weight', 'model.layers.5.self_attn.k_proj.weight', 'model.layers.5.self_attn.o_proj.weight', 'model.layers.5.self_attn.q_proj.weight', 'model.layers.5.self_attn.v_proj.weight', 'model.layers.6.mlp.down_proj.weight', 'model.layers.6.mlp.gate_proj.weight', 'model.layers.6.mlp.up_proj.weight', 'model.layers.6.self_attn.k_proj.weight', 'model.layers.6.self_attn.o_proj.weight', 'model.layers.6.self_attn.q_proj.weight', 'model.layers.6.self_attn.v_proj.weight', 'model.layers.7.mlp.down_proj.weight', 'model.layers.7.mlp.gate_proj.weight', 'model.layers.7.mlp.up_proj.weight', 'model.layers.7.self_attn.k_proj.weight', 'model.layers.7.self_attn.o_proj.weight', 'model.layers.7.self_attn.q_proj.weight', 'model.layers.7.self_attn.v_proj.weight', 'model.layers.8.mlp.down_proj.weight', 'model.layers.8.mlp.gate_proj.weight', 'model.layers.8.mlp.up_proj.weight', 'model.layers.8.self_attn.k_proj.weight', 'model.layers.8.self_attn.o_proj.weight', 'model.layers.8.self_attn.q_proj.weight', 'model.layers.8.self_attn.v_proj.weight', 'model.layers.9.mlp.down_proj.weight', 'model.layers.9.mlp.gate_proj.weight', 'model.layers.9.mlp.up_proj.weight', 'model.layers.9.self_attn.k_proj.weight', 'model.layers.9.self_attn.o_proj.weight', 'model.layers.9.self_attn.q_proj.weight', 'model.layers.9.self_attn.v_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2454a6cfce784ebf932f354d0e87569b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/183 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5df204860eef4a01872c0f8deae90f2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/765 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "735b5d5a35a7484ca5e7b25cf4ac8344",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/934k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ca71a9f08e7469c941e294b80f7e208",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/2.77M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ce0a0a76748496a97203c463c8a4c75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/434 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "NameError",
     "evalue": "name 'compute_label_embedding2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 51\u001b[0m\n\u001b[1;32m     48\u001b[0m LabelEmbedding\u001b[38;5;241m=\u001b[39m{}\n\u001b[1;32m     49\u001b[0m ArticleEmbedding\u001b[38;5;241m=\u001b[39m[]\n\u001b[0;32m---> 51\u001b[0m LabelEmbedding\u001b[38;5;241m=\u001b[39m \u001b[43mcompute_label_embedding2\u001b[49m(model, tokenizer)\n\u001b[1;32m     52\u001b[0m ArticleEmbedding\u001b[38;5;241m=\u001b[39m compute_article_embedding(model, tokenizer)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'compute_label_embedding2' is not defined"
     ]
    }
   ],
   "source": [
    "dataset_path=\"/kaggle/input/dataset-multi-class-classification/NewsBlog_ProthomAlo_FinalDataset.json\"\n",
    "result_path=\"/kaggle/working/output(1000-2000)\"\n",
    "\n",
    "#torch.cuda.empty_cache()\n",
    "#device_map={\"\": 0}\n",
    "#Load the model here\n",
    "base_model = \"BanglaLLM/bangla-llama-13b-instruct-v0.1\" \n",
    "\n",
    "base_model_name = base_model\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    base_model_name,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=\"float16\",\n",
    "    quantization_config=bnb_config, \n",
    ")\n",
    "model.gradient_checkpointing_enable()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "model.config.use_cache = False\n",
    "model.config.pretraining_tp = 1\n",
    "# model = AutoModel.from_pretrained(base_model_name, device_map=\"auto\", offload_folder=\"offload\")\n",
    "# model.gradient_checkpointing_enable()\n",
    "# Load the tokenizer here if needed\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model_name, use_fast=True, trust_remote_code=True)\n",
    "\n",
    "#LaBSE implementation\n",
    "# model = SentenceTransformer('sentence-transformers/LaBSE')\n",
    "\n",
    "#LASER implementation\n",
    "# laser = Laser()\n",
    "\n",
    "# Bangla transformer implementation\n",
    "# transformer=Bangla_sentence_transformer_small()\n",
    "\n",
    "\n",
    "#Bloom implementation\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"bigscience/bloomz-1b1\")\n",
    "# model = BloomModel.from_pretrained(\"bigscience/bloomz-1b1\")\n",
    "\n",
    "\n",
    "#Flan-UL2 implementation\n",
    "# model = AutoModelForSeq2SeqLM.from_pretrained(\"google/flan-ul2\")\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"google/flan-ul2\")\n",
    "\n",
    "#GPTNeoX implementation\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"EleutherAI/gpt-neox-20b\")\n",
    "# model = GPTNeoXModel.from_pretrained(\"EleutherAI/gpt-neox-20b\")\n",
    "LabelEmbedding={}\n",
    "ArticleEmbedding=[]\n",
    "\n",
    "LabelEmbedding= compute_label_embedding2(model, tokenizer)\n",
    "ArticleEmbedding= compute_article_embedding(model, tokenizer)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-01-31T02:23:50.048298Z",
     "iopub.status.idle": "2025-01-31T02:23:50.048589Z",
     "shell.execute_reply": "2025-01-31T02:23:50.048467Z",
     "shell.execute_reply.started": "2025-01-31T02:23:50.048454Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-01-31T02:23:50.049992Z",
     "iopub.status.idle": "2025-01-31T02:23:50.050377Z",
     "shell.execute_reply": "2025-01-31T02:23:50.050227Z",
     "shell.execute_reply.started": "2025-01-31T02:23:50.050210Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for threshold in np.arange(0.95,0.99,0.05):\n",
    "        final_article_list = []\n",
    "        print(\"Threshold running for::\",threshold)\n",
    "        filename = str(threshold) + '_NewsBlog_ProthomAlo_Dataset.json'\n",
    "        for i in range(0, len(ArticleEmbedding)):\n",
    "            inferred_label=[]\n",
    "            final_article = {}\n",
    "            for label in LabelEmbedding:\n",
    "                x = ArticleEmbedding[i]['Article Embedding']\n",
    "                #.hidden_states[-1]\n",
    "                label_embedding_np = LabelEmbedding[label].cpu().numpy().flatten()\n",
    "                squeezed_embedding_np = x.flatten()\n",
    "                squeezed_embedding_np = [np.mean(squeezed_embedding_np)]\n",
    "                label_embedding_np = [np.mean(label_embedding_np)]\n",
    "                # print(label_embedding_np)\n",
    "                # print(squeezed_embedding_np)\n",
    "                cosine_dist = 1 - spatial.distance.cosine(label_embedding_np, squeezed_embedding_np)\n",
    "                #print(cosine_dist)\n",
    "                if (cosine_dist > threshold):\n",
    "                    inferred_label.append(label)\n",
    "            # #random function to pick 5 labels.\n",
    "            #then send as the output label\n",
    "            # sample_size = min(len(inferred_label), 8)\n",
    "            # inferred_label = random.sample(inferred_label, sample_size)\n",
    "            final_article['Article Text'] = ArticleEmbedding[i]['Article Text']\n",
    "            final_article['Inferred Article Label'] = inferred_label # inferred labels\n",
    "            final_article['Label'] = ArticleEmbedding[i]['Label']  # ground truth labels added for evaluation\n",
    "            final_article_list.append(final_article)\n",
    "\n",
    "        with open(result_path+filename, 'w', encoding='utf-8', newline='\\n') as f:\n",
    "            #print(\"writing json::\",filename)\n",
    "            json.dump(final_article_list, f, ensure_ascii=False, indent=4, separators=(',', ':'))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-01-24T08:10:25.656Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# import json\n",
    "\n",
    "# # Function to decode Unicode-escaped Bangla text in JSON file\n",
    "# def decode_bangla_json(input_file, output_file):\n",
    "#     # Open and read the JSON file\n",
    "#     with open(input_file, 'r', encoding='utf-8') as f:\n",
    "#         data = json.load(f)\n",
    "\n",
    "#     # Save the JSON data with the correct encoding\n",
    "#     with open(output_file, 'w', encoding='utf-8') as f:\n",
    "#         json.dump(data, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "# # Input and output file paths\n",
    "# input_file = '/kaggle/input/unicoded-bangla/output0.9500000000000001_NewsBlog_ProthomAlo_Dataset.json'  # Replace with your input JSON file path\n",
    "# output_file = '/kaggle/working/decoded_bangla_output.json'  # Replace with your desired output file path\n",
    "\n",
    "# # Call the function to decode Unicode-escaped text\n",
    "# decode_bangla_json(input_file, output_file)\n",
    "\n",
    "# print(f\"Decoded JSON file saved to: {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 5897384,
     "sourceId": 9654282,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5914932,
     "sourceId": 9677686,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30786,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
